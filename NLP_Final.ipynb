{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "JBU3cdpk17W1",
   "metadata": {
    "id": "JBU3cdpk17W1"
   },
   "source": [
    "## Retrieve data from sqllite db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fddb98",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f6fddb98",
    "outputId": "987a4e64-898b-4070-ce61-80c576143ad0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-4db6eaca-cbc8-4ca1-b4e6-941612984ad5\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>dialect</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@toha_Altomy @gy_yah قليلين ادب ومنافقين. لو ا...</td>\n",
       "      <td>LY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@AlmFaisal 😂😂 الليبيين متقلبين!!!\\nبس بالنسبة ...</td>\n",
       "      <td>LY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@smsm071990 @ALMOGRBE كل 20 تانيه شاب ليبي بير...</td>\n",
       "      <td>LY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@AboryPro @lyranoo85 رانيا عقليتك متخلفة. اولا...</td>\n",
       "      <td>LY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@lyranoo85 شكلك متعقدة علشان الراجل لي تحبيه ا...</td>\n",
       "      <td>LY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4db6eaca-cbc8-4ca1-b4e6-941612984ad5')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-4db6eaca-cbc8-4ca1-b4e6-941612984ad5 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-4db6eaca-cbc8-4ca1-b4e6-941612984ad5');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                               tweet dialect\n",
       "0  @toha_Altomy @gy_yah قليلين ادب ومنافقين. لو ا...      LY\n",
       "1  @AlmFaisal 😂😂 الليبيين متقلبين!!!\\nبس بالنسبة ...      LY\n",
       "2  @smsm071990 @ALMOGRBE كل 20 تانيه شاب ليبي بير...      LY\n",
       "3  @AboryPro @lyranoo85 رانيا عقليتك متخلفة. اولا...      LY\n",
       "4  @lyranoo85 شكلك متعقدة علشان الراجل لي تحبيه ا...      LY"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "conn = sqlite3.connect('./Data/dialects_database.db')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "cursor.execute(\"SELECT * FROM id_text\")\n",
    "text = cursor.fetchall()\n",
    "text_df = pd.DataFrame(text, columns=['id', 'tweet'])\n",
    "\n",
    "cursor.execute(\"SELECT * FROM id_dialect\")\n",
    "dialect = cursor.fetchall()\n",
    "dialect_df = pd.DataFrame(dialect, columns=['id', 'dialect'])\n",
    "\n",
    "cursor.close()\n",
    "conn.close()\n",
    "\n",
    "df = pd.merge(text_df, dialect_df, on=\"id\")\n",
    "df.drop(['id'], axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ZRjGKeXk3PBz",
   "metadata": {
    "id": "ZRjGKeXk3PBz"
   },
   "source": [
    "## Data prepration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e009e3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "91e009e3",
    "outputId": "ccfd6ba0-ef99-45bc-87ee-3ab475708349"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicates: 0\n"
     ]
    }
   ],
   "source": [
    "num_duplicates = df.duplicated().sum()\n",
    "print('Number of duplicates:', num_duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b384448",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5b384448",
    "outputId": "bc811c2c-8825-472e-cda3-d30a34e78a47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class counts:\n",
      "EG    57636\n",
      "LY    36499\n",
      "LB    27617\n",
      "SD    14434\n",
      "MA    11539\n",
      "Name: dialect, dtype: int64\n",
      "Class proportions:\n",
      "EG    0.390157\n",
      "LY    0.247074\n",
      "LB    0.186949\n",
      "SD    0.097709\n",
      "MA    0.078111\n",
      "Name: dialect, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "class_counts = df['dialect'].value_counts()\n",
    "class_proportions = df['dialect'].value_counts(normalize=True)\n",
    "\n",
    "print('Class counts:')\n",
    "print(class_counts)\n",
    "\n",
    "print('Class proportions:')\n",
    "print(class_proportions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Kau33sKv3W3h",
   "metadata": {
    "id": "Kau33sKv3W3h"
   },
   "source": [
    "## Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2812f9ba",
   "metadata": {
    "id": "2812f9ba"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "def tokenize_tweet(tweet):\n",
    "    # create a TweetTokenizer object\n",
    "    tknzr = TweetTokenizer()\n",
    "    # tokenize the tweet\n",
    "    tokens = tknzr.tokenize(tweet)\n",
    "    return tokens\n",
    "tokenized = tokenize_tweet(df['tweet'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d09a251",
   "metadata": {
    "id": "4d09a251"
   },
   "outputs": [],
   "source": [
    "def remove_extra_spaces(words):\n",
    "    \"\"\"Removes extra whitespaces at the beginning and at the end of each word in a list\"\"\"\n",
    "    cleaned_words = []\n",
    "    for word in words:\n",
    "        cleaned_word = ' '.join(word.split()).strip()\n",
    "        cleaned_words.append(cleaned_word)\n",
    "    return cleaned_words\n",
    "r_e_s = remove_extra_spaces(tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acdac67",
   "metadata": {
    "id": "0acdac67"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def remove_urls(lst):\n",
    "    pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return [re.sub(pattern, '', item).strip() for item in lst if re.sub(pattern, '', item).strip() != '']\n",
    "r_urls = remove_urls(r_e_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e7251d",
   "metadata": {
    "id": "19e7251d"
   },
   "outputs": [],
   "source": [
    "def remove_user_mentions(words):\n",
    "    \"\"\"Removes user mentions (@user) from a list of words\"\"\"\n",
    "    cleaned_words = []\n",
    "    for word in words:\n",
    "        if not word.startswith('@'):\n",
    "            cleaned_words.append(word)\n",
    "    return cleaned_words\n",
    "r_u_m = remove_user_mentions(r_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bd37cd",
   "metadata": {
    "id": "e3bd37cd"
   },
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def remove_punctuation(lst):\n",
    "    \"\"\"Removes punctuation from a list of strings, including single punctuation characters\"\"\"\n",
    "    translator = str.maketrans('', '', string.punctuation+'؟')\n",
    "    result = []\n",
    "    for item in lst:\n",
    "        # Remove all punctuation characters\n",
    "        item = item.translate(translator)\n",
    "        # Remove any remaining single punctuation characters\n",
    "        if item != '':\n",
    "          result.append(item)\n",
    "    return result\n",
    "r_p = remove_punctuation(r_u_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757f779c",
   "metadata": {
    "id": "757f779c"
   },
   "outputs": [],
   "source": [
    "def remove_numbers(lst):\n",
    "    \"\"\"Removes numbers from a list of strings\"\"\"\n",
    "    pattern = re.compile(r'\\d+')\n",
    "    return [re.sub(pattern, '', item) for item in lst if re.sub(pattern, '', item).strip() != '']\n",
    "r_n = remove_numbers(r_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51402811",
   "metadata": {
    "id": "51402811"
   },
   "outputs": [],
   "source": [
    "import emoji\n",
    "def remove_emojis(words):\n",
    "    \"\"\"Removes emojis from a list of words\"\"\"\n",
    "    cleaned_words = []\n",
    "    for word in words:\n",
    "        cleaned_word = ''.join(c for c in word if c not in emoji.EMOJI_DATA)\n",
    "        if cleaned_word != '':\n",
    "            cleaned_words.append(cleaned_word)\n",
    "    return cleaned_words\n",
    "r_e = remove_emojis(r_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50d70fd",
   "metadata": {
    "id": "f50d70fd"
   },
   "outputs": [],
   "source": [
    "def remove_foreign_language(lst):\n",
    "    pattern = re.compile(r'[^\\u0600-\\u06ff]+')\n",
    "    return [re.sub(pattern, \"\", item) for item in lst if re.sub(pattern, \"\", item) != '']\n",
    "\n",
    "r_f_l = remove_foreign_language(r_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7701792",
   "metadata": {
    "id": "f7701792"
   },
   "outputs": [],
   "source": [
    "from pyarabic.araby import strip_tashkeel\n",
    "from pyarabic.araby import normalize_ligature\n",
    "def remove_tashkeel(lst):\n",
    "    return [normalize_ligature(strip_tashkeel(word)) for word in lst]\n",
    "r_t = remove_tashkeel(r_f_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5edb36e6",
   "metadata": {
    "id": "5edb36e6"
   },
   "outputs": [],
   "source": [
    "def remove_repeated_chars(lst):\n",
    "    pattern = re.compile(r\"(\\w)\\1{2,}\")\n",
    "    return [re.sub(pattern, r\"\\1\\1\", item).strip() for item in lst if re.sub(pattern, '', item).strip() != '']\n",
    "\n",
    "r_r_c = remove_repeated_chars(r_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d897df30",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d897df30",
    "outputId": "902b80ae-675c-474d-b92e-f5ed3002ae35"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c011ddb9",
   "metadata": {
    "id": "c011ddb9"
   },
   "outputs": [],
   "source": [
    "STOP_WORDS = set(nltk.corpus.stopwords.words(\"arabic\"))\n",
    "\n",
    "def remove_stop_words(lst):\n",
    "    result = []\n",
    "    for word in lst:\n",
    "        if word not in STOP_WORDS:\n",
    "            result.append(word)\n",
    "    return result\n",
    "r_s_w = remove_stop_words(r_r_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af48ba68",
   "metadata": {
    "id": "af48ba68"
   },
   "outputs": [],
   "source": [
    "def form_sentence(words):\n",
    "    \"\"\"Forms a sentence from a list of words\"\"\"\n",
    "    sentence = ' '.join(words)\n",
    "    return sentence\n",
    "f_s = form_sentence(r_s_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5634c00",
   "metadata": {
    "id": "d5634c00"
   },
   "outputs": [],
   "source": [
    "def clean_tweet(tweet,mode=\"ml\"):\n",
    "    \"\"\"\n",
    "    A function to clean a single tweet.\n",
    "    \"\"\"\n",
    "    if mode==\"ml\":\n",
    "        #tokenize tweet \n",
    "        words = tokenize_tweet(tweet)\n",
    "        #remove extra white-spaces\n",
    "        words = remove_extra_spaces(words)\n",
    "        #remove urls \n",
    "        words = remove_urls(words)\n",
    "        #remove user mentions \n",
    "        words = remove_user_mentions(words)\n",
    "        #remove punctiation\n",
    "        words = remove_punctuation(words)\n",
    "        #remove numbers\n",
    "        words = remove_numbers(words)\n",
    "        #remove emojis\n",
    "        words = remove_emojis(words)\n",
    "        #remove non-arabic charachters\n",
    "        words = remove_foreign_language(words)\n",
    "        #remove tashkeel \n",
    "        words = remove_tashkeel(words)\n",
    "        #remove repeated charachters\n",
    "        words = remove_repeated_chars(words)\n",
    "        #remove stop words \n",
    "        words = remove_stop_words(words)\n",
    "        #form a new sentence\n",
    "        sentence = form_sentence(words)\n",
    "    else:\n",
    "        words = tokenize_tweet(tweet)\n",
    "        #remove extra white-spaces\n",
    "        words = remove_extra_spaces(words)\n",
    "        #remove urls \n",
    "        words = remove_urls(words)\n",
    "        #remove user mentions \n",
    "        words = remove_user_mentions(words)\n",
    "        #remove punctiation\n",
    "        words = remove_punctuation(words)\n",
    "        #remove numbers\n",
    "        words = remove_numbers(words)\n",
    "        #remove emojis\n",
    "        words = remove_emojis(words)\n",
    "        #remove non-arabic charachters\n",
    "        words = remove_foreign_language(words)\n",
    "        #form a new sentence\n",
    "        sentence = form_sentence(words)\n",
    "    return sentence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b348cb89",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 381
    },
    "id": "b348cb89",
    "outputId": "ae84aba3-5de8-41c7-a382-c76a959f29b2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 147725/147725 [00:00<00:00, 2335139.42it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-39c1c80a-e315-485d-90e2-424f67f43944\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>dialect</th>\n",
       "      <th>clean_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@toha_Altomy @gy_yah قليلين ادب ومنافقين. لو ا...</td>\n",
       "      <td>LY</td>\n",
       "      <td>قليلين ادب ومنافقين اختهم او قريبتهم تتعاكس تق...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@AlmFaisal 😂😂 الليبيين متقلبين!!!\\nبس بالنسبة ...</td>\n",
       "      <td>LY</td>\n",
       "      <td>الليبيين متقلبين بالنسبة ليا انا ميليشياوي زما...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@smsm071990 @ALMOGRBE كل 20 تانيه شاب ليبي بير...</td>\n",
       "      <td>LY</td>\n",
       "      <td>تانيه شاب ليبي بيرتاح لبنت مختلفة ويلاحظ انها ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@AboryPro @lyranoo85 رانيا عقليتك متخلفة. اولا...</td>\n",
       "      <td>LY</td>\n",
       "      <td>رانيا عقليتك متخلفة اولا الانسان يلي يحتاج اهل...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@lyranoo85 شكلك متعقدة علشان الراجل لي تحبيه ا...</td>\n",
       "      <td>LY</td>\n",
       "      <td>شكلك متعقدة علشان الراجل تحبيه ازوج بنت يتيمة ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>@alibobkr63 او حتى من اي دين او طائفة. اسف ممك...</td>\n",
       "      <td>LY</td>\n",
       "      <td>او اي دين او طائفة اسف ممكن الغلط غلطتي مكنش قصدي</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>@muhamed01111 باهي نستنوه. بلكي مشغول ولا حاجة</td>\n",
       "      <td>LY</td>\n",
       "      <td>باهي نستنوه بلكي مشغول حاجة</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>@muhamed01111 مهما اختلفنا راه نحنا خوت. والله...</td>\n",
       "      <td>LY</td>\n",
       "      <td>اختلفنا راه نحنا خوت والله عندي انا فرحان نقدر...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>@muhamed01111 بالنسبة ليا انا والله شبعت هم ون...</td>\n",
       "      <td>LY</td>\n",
       "      <td>بالنسبة ليا انا والله شبعت ونكد وقتل ودم والحق...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>@Ajo32asLibya @Jed_ly مو نحنا الحياة عندنا مية...</td>\n",
       "      <td>LY</td>\n",
       "      <td>مو نحنا الحياة عندنا مية مية ومعندش شي اندكوا ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-39c1c80a-e315-485d-90e2-424f67f43944')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-39c1c80a-e315-485d-90e2-424f67f43944 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-39c1c80a-e315-485d-90e2-424f67f43944');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                               tweet dialect  \\\n",
       "0  @toha_Altomy @gy_yah قليلين ادب ومنافقين. لو ا...      LY   \n",
       "1  @AlmFaisal 😂😂 الليبيين متقلبين!!!\\nبس بالنسبة ...      LY   \n",
       "2  @smsm071990 @ALMOGRBE كل 20 تانيه شاب ليبي بير...      LY   \n",
       "3  @AboryPro @lyranoo85 رانيا عقليتك متخلفة. اولا...      LY   \n",
       "4  @lyranoo85 شكلك متعقدة علشان الراجل لي تحبيه ا...      LY   \n",
       "5  @alibobkr63 او حتى من اي دين او طائفة. اسف ممك...      LY   \n",
       "6     @muhamed01111 باهي نستنوه. بلكي مشغول ولا حاجة      LY   \n",
       "7  @muhamed01111 مهما اختلفنا راه نحنا خوت. والله...      LY   \n",
       "8  @muhamed01111 بالنسبة ليا انا والله شبعت هم ون...      LY   \n",
       "9  @Ajo32asLibya @Jed_ly مو نحنا الحياة عندنا مية...      LY   \n",
       "\n",
       "                                         clean_tweet  \n",
       "0  قليلين ادب ومنافقين اختهم او قريبتهم تتعاكس تق...  \n",
       "1  الليبيين متقلبين بالنسبة ليا انا ميليشياوي زما...  \n",
       "2  تانيه شاب ليبي بيرتاح لبنت مختلفة ويلاحظ انها ...  \n",
       "3  رانيا عقليتك متخلفة اولا الانسان يلي يحتاج اهل...  \n",
       "4  شكلك متعقدة علشان الراجل تحبيه ازوج بنت يتيمة ...  \n",
       "5  او اي دين او طائفة اسف ممكن الغلط غلطتي مكنش قصدي  \n",
       "6                        باهي نستنوه بلكي مشغول حاجة  \n",
       "7  اختلفنا راه نحنا خوت والله عندي انا فرحان نقدر...  \n",
       "8  بالنسبة ليا انا والله شبعت ونكد وقتل ودم والحق...  \n",
       "9  مو نحنا الحياة عندنا مية مية ومعندش شي اندكوا ...  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "df['clean_tweet'] = tqdm(df['tweet'].apply(clean_tweet,args=(\"ml\",)))\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822195d5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "822195d5",
    "outputId": "20bc5b43-d6a9-453e-84e0-ef54da5dfd95"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "\n",
    "df.clean_tweet = df.clean_tweet.replace('',np.NaN)\n",
    "print(df['clean_tweet'].isnull().values.sum())\n",
    "\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3111ec3b",
   "metadata": {
    "id": "3111ec3b"
   },
   "outputs": [],
   "source": [
    "df = df[['clean_tweet','dialect']]\n",
    "df.to_csv(\"./Data/clean_df.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "j222BOT-XDOy",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j222BOT-XDOy",
    "outputId": "a94ddd24-0147-481d-c8f5-4700b123bdcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(147652, 2)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "df = pd.read_csv('./Data/clean_df.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9202f49a",
   "metadata": {
    "id": "9202f49a"
   },
   "outputs": [],
   "source": [
    "# from ar_wordcloud import ArabicWordCloud\n",
    "\n",
    "# text = \" \".join(i for i in df.clean_tweet)\n",
    "# awc = ArabicWordCloud(background_color=\"white\")\n",
    "# awc.from_text(text).to_image()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fGcQPQLK3eUy",
   "metadata": {
    "id": "fGcQPQLK3eUy"
   },
   "source": [
    "## Train ML models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "55389a3c",
   "metadata": {
    "id": "55389a3c"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df[\"clean_tweet\"].astype('U').values.tolist()\n",
    "y = df[\"dialect\"].astype('U').values.tolist()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc167017",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "id": "bc167017",
    "outputId": "2cd88d28-d091-404e-91b8-42027c5b9c58"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TfidfVectorizer(ngram_range=(1, 3))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(ngram_range=(1, 3))</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "TfidfVectorizer(ngram_range=(1, 3))"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "corpus = X_train\n",
    "# Initizalize the vectorizer with max nr words and ngrams (1: single words, 2: two words in a row)\n",
    "vectorizer_tfidf = TfidfVectorizer(ngram_range=(1,3))\n",
    "#corpus = vectorizer_tfidf.fit_transform(corpus.apply(lambda x: np.str_(x)))\n",
    "# Fit the vectorizer to the training data\n",
    "vectorizer_tfidf.fit(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "F25lIw30fCW0",
   "metadata": {
    "id": "F25lIw30fCW0"
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "def evaluate_model(model, X_test, y_test,model_type=None):\n",
    "  \"\"\" Evaluates a model on test data\n",
    "\n",
    "  Args:\n",
    "    model: The model to evaluate.\n",
    "    test_data: The test data.\n",
    "\n",
    "  Returns:\n",
    "    The accuracy score and f1 macro score.\n",
    "\n",
    "  \"\"\"\n",
    "  if model_type == 'DL':\n",
    "        loss, accuracy = model.evaluate(X_test,y_test)\n",
    "        probabilites = model.predict(X_test)\n",
    "        predictions = probabilites.argmax(axis=-1)\n",
    "        y_test = y_test.argmax(axis=-1)\n",
    "  else:\n",
    "      # Make predictions on the test data.\n",
    "      predictions = model.predict(X_test)\n",
    "\n",
    "      # Calculate the accuracy score.\n",
    "      accuracy = accuracy_score(y_test, predictions)\n",
    "\n",
    "  # Calculate the f1 macro score.\n",
    "  f1_macro = f1_score(y_test, predictions, average=\"macro\")\n",
    "\n",
    "  # Print the results.\n",
    "  print(\"Accuracy:\", accuracy)\n",
    "  print(\"F1 macro:\", f1_macro)\n",
    "\n",
    "  report = metrics.classification_report(y_test, predictions)\n",
    "  print(report)\n",
    "\n",
    "  return accuracy, f1_macro, report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "270362be",
   "metadata": {
    "id": "270362be"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import keras\n",
    "def save_model(model, filename, mode=None):\n",
    "  \"\"\"Saves a model to a .pkl file.\n",
    "\n",
    "  Args:\n",
    "    model: The model to save.\n",
    "    filename: The name of the file to save the model to.\n",
    "\n",
    "  \"\"\"\n",
    "  if mode == 'DL':\n",
    "        model.save(filename)\n",
    "  else:\n",
    "      with open(filename, \"wb\") as f:\n",
    "        pickle.dump(model, f)\n",
    "\n",
    "def load_model(filename,mode=None):\n",
    "  \"\"\"Loads a model from a .pkl file.\n",
    "\n",
    "  Args:\n",
    "    filename: The name of the file to load the model from.\n",
    "\n",
    "  Returns:\n",
    "    The loaded model.\n",
    "\n",
    "  \"\"\"\n",
    "  if mode == 'DL':\n",
    "        model = keras.models.load_model(filename)\n",
    "  else:     \n",
    "      with open(filename, \"rb\") as f:\n",
    "        model = pickle.load(f)\n",
    "\n",
    "  return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kixyLeej4EaZ",
   "metadata": {
    "id": "kixyLeej4EaZ"
   },
   "source": [
    "## Multinomialnb Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5051c9a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "id": "e5051c9a",
    "outputId": "a574fdf7-d65d-4700-85d4-495a5043baf4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;vectorizer&#x27;, TfidfVectorizer(ngram_range=(1, 3))),\n",
       "                (&#x27;classifier&#x27;, MultinomialNB())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;vectorizer&#x27;, TfidfVectorizer(ngram_range=(1, 3))),\n",
       "                (&#x27;classifier&#x27;, MultinomialNB())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(ngram_range=(1, 3))</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('vectorizer', TfidfVectorizer(ngram_range=(1, 3))),\n",
       "                ('classifier', MultinomialNB())])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "classifier_tfidf_NB = MultinomialNB()\n",
    "model_tfidf_NB = Pipeline([(\"vectorizer\", vectorizer_tfidf), (\"classifier\", classifier_tfidf_NB)])\n",
    "\n",
    "model_tfidf_NB.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "OGqQUZwb4YSy",
   "metadata": {
    "id": "OGqQUZwb4YSy"
   },
   "source": [
    "## Evalution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Gh6Q7TWBfQi3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gh6Q7TWBfQi3",
    "outputId": "be0b3f9c-3882-4af8-c748-789ff310b507"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6653799268590004\n",
      "F1 macro: 0.5056611076652915\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          EG       0.56      1.00      0.72      5762\n",
      "          LB       0.96      0.62      0.75      2762\n",
      "          LY       0.85      0.58      0.69      3648\n",
      "          MA       1.00      0.16      0.27      1154\n",
      "          SD       1.00      0.05      0.09      1440\n",
      "\n",
      "    accuracy                           0.67     14766\n",
      "   macro avg       0.87      0.48      0.51     14766\n",
      "weighted avg       0.78      0.67      0.62     14766\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy, f1_macro, report = evaluate_model(model_tfidf_NB, X_test, y_test)\n",
    "save_model(model_tfidf_NB,'NB.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jysGEcVG4Jzy",
   "metadata": {
    "id": "jysGEcVG4Jzy"
   },
   "source": [
    "## linear SVC model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5df70a8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "id": "a5df70a8",
    "outputId": "00710af2-ee3a-4654-a1f3-b490967adf42"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;vectorizer&#x27;, TfidfVectorizer(ngram_range=(1, 3))),\n",
       "                (&#x27;classifier&#x27;, LinearSVC())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;vectorizer&#x27;, TfidfVectorizer(ngram_range=(1, 3))),\n",
       "                (&#x27;classifier&#x27;, LinearSVC())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(ngram_range=(1, 3))</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearSVC</label><div class=\"sk-toggleable__content\"><pre>LinearSVC()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('vectorizer', TfidfVectorizer(ngram_range=(1, 3))),\n",
       "                ('classifier', LinearSVC())])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from nltk.classify import SklearnClassifier\n",
    "\n",
    "classifier_tfidf_SVC = LinearSVC()\n",
    "#classifier_tfidf_SVC = SVC(kernel='linear',probability=True)\n",
    "#classifier_tfidf_SVC = SklearnClassifier(SVC(kernel='linear',probability=True))\n",
    "\n",
    "model_tfidf_SVC = Pipeline([(\"vectorizer\", vectorizer_tfidf), (\"classifier\", classifier_tfidf_SVC)])\n",
    "\n",
    "model_tfidf_SVC.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2zRpKDhI4c17",
   "metadata": {
    "id": "2zRpKDhI4c17"
   },
   "source": [
    "## Evalution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4k8J_DMKfx27",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4k8J_DMKfx27",
    "outputId": "4b20c1f5-6f0b-4a44-8eb3-e7dd7a1aaa4a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8365840444263849\n",
      "F1 macro: 0.8047681802874983\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          EG       0.83      0.93      0.88      5762\n",
      "          LB       0.86      0.86      0.86      2762\n",
      "          LY       0.83      0.81      0.82      3648\n",
      "          MA       0.87      0.68      0.77      1154\n",
      "          SD       0.82      0.62      0.70      1440\n",
      "\n",
      "    accuracy                           0.84     14766\n",
      "   macro avg       0.84      0.78      0.80     14766\n",
      "weighted avg       0.84      0.84      0.83     14766\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy, f1_macro, report = evaluate_model(model_tfidf_SVC, X_test, y_test)\n",
    "#save_model(model_tfidf_SVC,'SVC.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "SgpHuacp4ium",
   "metadata": {
    "id": "SgpHuacp4ium"
   },
   "source": [
    "## Traim DL Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3b3664",
   "metadata": {
    "id": "7e3b3664"
   },
   "outputs": [],
   "source": [
    "# one_hot_repr = to_categorical([0,1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8367c3",
   "metadata": {
    "id": "ae8367c3"
   },
   "outputs": [],
   "source": [
    "# encoder.inverse_transform([2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ZmnjiEkLtbOB",
   "metadata": {
    "id": "ZmnjiEkLtbOB"
   },
   "outputs": [],
   "source": [
    "# from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# def classify_sentence(model, sentence, model_type=None,max_seq_length=None,encoder_type=None,encoder=None):\n",
    "#   \"\"\"Classifies a sentence using a model.\n",
    "\n",
    "#   Args:\n",
    "#     model: The model to use for classification.\n",
    "#     sentence: The sentence to classify.\n",
    "\n",
    "#   Returns:\n",
    "#     A tuple of the predicted label and the predicted probabilities for each class.\n",
    "\n",
    "#   \"\"\"\n",
    "#   if model_type == 'DL' and max_seq_length != None:\n",
    "#         tokenized_tweet = tokenize_and_pad_tweet(sentence,max_seq_length)\n",
    "#         probabilities_array = model.predict(tokenized_tweet)\n",
    "#         predicted_probabilities = probabilities_array.tolist()[0]\n",
    "#         predicted_label = probabilities_array.argmax(axis=-1)\n",
    "#         one_hot_repr = (probabilities_array == probabilities_array.max(axis=1)[:,None]).astype(int)\n",
    "#         if encoder_type == 'onehot':\n",
    "#             predicted_dialect = encoder.inverse_transform(one_hot_repr)[0]\n",
    "#             print(f\"predicted Dialect is {predicted_dialect[0]} \\n\")\n",
    "#             for i in range(len(encoder.categories_[0])):\n",
    "#                 print(f\"predicted Dialect {encoder.categories_[0][i]} with probability {predicted_probabilities[i]*100} \\n\")\n",
    "#         elif encoder_type == 'label':\n",
    "#             predicted_dialect = encoder.inverse_transform([predicted_label])\n",
    "#             print(f\"predicted Dialect is {predicted_dialect[0]} \\n\")         \n",
    "#             for i in range(len(encoder.classes_)):\n",
    "#                 print(f\"predicted Dialect {encoder.classes_[i]} with probability {predicted_probabilities[i]*100} \\n\")         \n",
    "                    \n",
    "#   else:\n",
    "#       # Make a prediction.\n",
    "#       predicted_label = model.predict([sentence])\n",
    "#       print(f\"predicted Dialect is {predicted_label[0]} \\n\")\n",
    "\n",
    "#       # Get the predicted probabilities for each class.\n",
    "#       predicted_probabilities = None\n",
    "#       try:\n",
    "#         predicted_probabilities = model.predict_proba([sentence]).tolist()[0]\n",
    "#         for i in range(len(model.classes_)):\n",
    "#           print(f\"predicted Dialect {model.classes_[i]} with probability {predicted_probabilities[i]*100} \\n\")\n",
    "\n",
    "#       except AttributeError:\n",
    "#         print(\"Model doesn't support predicting probabilites\")\n",
    "\n",
    "#   return predicted_label, predicted_probabilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "512ef0a5",
   "metadata": {
    "id": "512ef0a5"
   },
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('./Data/dialects_database.db')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "cursor.execute(\"SELECT * FROM id_text\")\n",
    "text = cursor.fetchall()\n",
    "text_df = pd.DataFrame(text, columns=['id', 'tweet'])\n",
    "\n",
    "cursor.execute(\"SELECT * FROM id_dialect\")\n",
    "dialect = cursor.fetchall()\n",
    "dialect_df = pd.DataFrame(dialect, columns=['id', 'dialect'])\n",
    "\n",
    "cursor.close()\n",
    "conn.close()\n",
    "\n",
    "df = pd.merge(text_df, dialect_df, on=\"id\")\n",
    "df.drop(['id'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1c9edcae",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 381
    },
    "id": "1c9edcae",
    "outputId": "40d64d3b-d939-4bb8-b2af-b790f09354ae",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 147725/147725 [00:00<00:00, 2677734.04it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-209d690d-ce6f-443c-9a55-6268ff5ee72c\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>dialect</th>\n",
       "      <th>clean_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@toha_Altomy @gy_yah قليلين ادب ومنافقين. لو ا...</td>\n",
       "      <td>LY</td>\n",
       "      <td>قليلين ادب ومنافقين لو اختهم او قريبتهم تتعاكس...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@AlmFaisal 😂😂 الليبيين متقلبين!!!\\nبس بالنسبة ...</td>\n",
       "      <td>LY</td>\n",
       "      <td>الليبيين متقلبين بس بالنسبة ليا انا ميليشياوي ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@smsm071990 @ALMOGRBE كل 20 تانيه شاب ليبي بير...</td>\n",
       "      <td>LY</td>\n",
       "      <td>كل تانيه شاب ليبي بيرتاح لبنت مختلفة ويلاحظ ان...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@AboryPro @lyranoo85 رانيا عقليتك متخلفة. اولا...</td>\n",
       "      <td>LY</td>\n",
       "      <td>رانيا عقليتك متخلفة اولا الانسان يلي يحتاج اهل...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@lyranoo85 شكلك متعقدة علشان الراجل لي تحبيه ا...</td>\n",
       "      <td>LY</td>\n",
       "      <td>شكلك متعقدة علشان الراجل لي تحبيه ازوج بنت يتي...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>@alibobkr63 او حتى من اي دين او طائفة. اسف ممك...</td>\n",
       "      <td>LY</td>\n",
       "      <td>او حتى من اي دين او طائفة اسف ممكن الغلط غلطتي...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>@muhamed01111 باهي نستنوه. بلكي مشغول ولا حاجة</td>\n",
       "      <td>LY</td>\n",
       "      <td>باهي نستنوه بلكي مشغول ولا حاجة</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>@muhamed01111 مهما اختلفنا راه نحنا خوت. والله...</td>\n",
       "      <td>LY</td>\n",
       "      <td>مهما اختلفنا راه نحنا خوت والله ما عندي عدا عل...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>@muhamed01111 بالنسبة ليا انا والله شبعت هم ون...</td>\n",
       "      <td>LY</td>\n",
       "      <td>بالنسبة ليا انا والله شبعت هم ونكد وقتل ودم وا...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>@Ajo32asLibya @Jed_ly مو نحنا الحياة عندنا مية...</td>\n",
       "      <td>LY</td>\n",
       "      <td>مو نحنا الحياة عندنا مية في مية ومعندش شي اندك...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-209d690d-ce6f-443c-9a55-6268ff5ee72c')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-209d690d-ce6f-443c-9a55-6268ff5ee72c button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-209d690d-ce6f-443c-9a55-6268ff5ee72c');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                               tweet dialect  \\\n",
       "0  @toha_Altomy @gy_yah قليلين ادب ومنافقين. لو ا...      LY   \n",
       "1  @AlmFaisal 😂😂 الليبيين متقلبين!!!\\nبس بالنسبة ...      LY   \n",
       "2  @smsm071990 @ALMOGRBE كل 20 تانيه شاب ليبي بير...      LY   \n",
       "3  @AboryPro @lyranoo85 رانيا عقليتك متخلفة. اولا...      LY   \n",
       "4  @lyranoo85 شكلك متعقدة علشان الراجل لي تحبيه ا...      LY   \n",
       "5  @alibobkr63 او حتى من اي دين او طائفة. اسف ممك...      LY   \n",
       "6     @muhamed01111 باهي نستنوه. بلكي مشغول ولا حاجة      LY   \n",
       "7  @muhamed01111 مهما اختلفنا راه نحنا خوت. والله...      LY   \n",
       "8  @muhamed01111 بالنسبة ليا انا والله شبعت هم ون...      LY   \n",
       "9  @Ajo32asLibya @Jed_ly مو نحنا الحياة عندنا مية...      LY   \n",
       "\n",
       "                                         clean_tweet  \n",
       "0  قليلين ادب ومنافقين لو اختهم او قريبتهم تتعاكس...  \n",
       "1  الليبيين متقلبين بس بالنسبة ليا انا ميليشياوي ...  \n",
       "2  كل تانيه شاب ليبي بيرتاح لبنت مختلفة ويلاحظ ان...  \n",
       "3  رانيا عقليتك متخلفة اولا الانسان يلي يحتاج اهل...  \n",
       "4  شكلك متعقدة علشان الراجل لي تحبيه ازوج بنت يتي...  \n",
       "5  او حتى من اي دين او طائفة اسف ممكن الغلط غلطتي...  \n",
       "6                    باهي نستنوه بلكي مشغول ولا حاجة  \n",
       "7  مهما اختلفنا راه نحنا خوت والله ما عندي عدا عل...  \n",
       "8  بالنسبة ليا انا والله شبعت هم ونكد وقتل ودم وا...  \n",
       "9  مو نحنا الحياة عندنا مية في مية ومعندش شي اندك...  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['clean_tweet'] = tqdm(df['tweet'].apply(clean_tweet,args=(\"dl\",)))\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "94843f63",
   "metadata": {
    "id": "94843f63"
   },
   "outputs": [],
   "source": [
    "X = df[\"clean_tweet\"].astype('U').values.tolist()\n",
    "y = df[\"dialect\"].astype('U').values.tolist()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ksFsFrhoC_N2",
   "metadata": {
    "id": "ksFsFrhoC_N2"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import tkseem as tk\n",
    "\n",
    "\n",
    "def tokenize_and_pad_tweets(data,datatype= 'train',max_words=None,max_seq_len=None,model_path= './tokenizer_model.pkl'):\n",
    "    \"\"\"Tokenizes tweets and pads the sequences to the length of the longest sequence in the dataset.\n",
    "\n",
    "    Args:\n",
    "        df_column (pandas.Series): A DataFrame column containing tweets.\n",
    "\n",
    "    Returns:\n",
    "        tuple:\n",
    "            numpy.ndarray: An array of padded sequences.\n",
    "            int: The vocabulary size.\n",
    "            int: The maximum sequence length.\n",
    "            Tokenizer: The tokenizer object used for the tokenization.\n",
    "    \"\"\"\n",
    "    if max_words == None:\n",
    "          tokenizer = tk.WordTokenizer()\n",
    "    else:\n",
    "          tokenizer = tk.WordTokenizer(vocab_size=max_words)\n",
    "            \n",
    "    if datatype == 'train':\n",
    "        # Create tokenizer \n",
    "        path = './tokenizer.txt'\n",
    "        df = pd.DataFrame(data,columns=['tweet'])\n",
    "        df.to_csv(path, sep='\\n', header=False,index=False)\n",
    "\n",
    "        tokenizer.train(path)\n",
    "        \n",
    "        sequences = [tokenizer.encode(sentence) for sentence in data]\n",
    "        max_seq_len = max(len(seq) for seq in sequences)\n",
    "        \n",
    "        vocab_size = tokenizer.vocab_size\n",
    "        sequences = pad_sequences(sequences, maxlen=max_seq_len,value = 0, padding='post')\n",
    "         \n",
    "    \n",
    "        tokenizer.save_model('./tokenizer_model.pkl')\n",
    "    \n",
    "    elif datatype == 'test' and max_seq_len != None:\n",
    "        try:\n",
    "            tokenizer.load_model(model_path)\n",
    "            sequences = [tokenizer.encode(sentence) for sentence in data]\n",
    "            vocab_size = tokenizer.vocab_size\n",
    "            sequences = pad_sequences(sequences, maxlen=max_seq_len,value = 0, padding='post')\n",
    "            \n",
    "        except:\n",
    "            print(\"please check if tokenizer model is passed correctly!\")\n",
    "    \n",
    "    return sequences, vocab_size, max_seq_len, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "Y9bVXBlRIanc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y9bVXBlRIanc",
    "outputId": "6e449f7e-95db-469b-b6da-78d99de9dd2d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training WordTokenizer ...\n",
      "Saving as pickle file ...\n"
     ]
    }
   ],
   "source": [
    "train_padded_sequences, vocab_size, max_seq_length, tokenizer = tokenize_and_pad_tweets(X_train,'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e20e3998",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e20e3998",
    "outputId": "0cd00387-57d4-4c66-b7d5-c41f2778c47e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading as pickle file ...\n"
     ]
    }
   ],
   "source": [
    "test_padded_sequences, vocab_size, max_seq_length, tokenizer = tokenize_and_pad_tweets(X_test,'test',None,max_seq_length,'./tokenizer_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cadf761f",
   "metadata": {
    "id": "cadf761f"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder,LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "#creating instance of one-hot-encoder\n",
    "#encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "#train_labels = encoder.fit_transform(pd.DataFrame(y_train)).toarray()\n",
    "#test_labels = encoder.fit_transform(pd.DataFrame(y_test)).toarray()\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "train_labels = encoder.fit_transform(y_train)\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = encoder.transform(y_test)\n",
    "test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "TgSUSC1v4wMM",
   "metadata": {
    "id": "TgSUSC1v4wMM"
   },
   "source": [
    "## RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3defb59a",
   "metadata": {
    "id": "3defb59a"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense\n",
    "\n",
    "embedding_dim = 64\n",
    "rnn_units = 64\n",
    "# Define model architecture\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_seq_length))\n",
    "model.add(SimpleRNN(units=rnn_units))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(units=5, activation='softmax'))\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7ae96dbd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7ae96dbd",
    "outputId": "76685bc8-5a2f-4300-9566-c49b749888e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2078/2078 [==============================] - 221s 103ms/step - loss: 1.4405 - accuracy: 0.3942 - val_loss: 1.3751 - val_accuracy: 0.4321\n",
      "Epoch 2/10\n",
      "2078/2078 [==============================] - 173s 83ms/step - loss: 1.2185 - accuracy: 0.5289 - val_loss: 1.0906 - val_accuracy: 0.6016\n",
      "Epoch 3/10\n",
      "2078/2078 [==============================] - 169s 82ms/step - loss: 1.0171 - accuracy: 0.6299 - val_loss: 1.0282 - val_accuracy: 0.6242\n",
      "Epoch 4/10\n",
      "2078/2078 [==============================] - 163s 79ms/step - loss: 0.9744 - accuracy: 0.6500 - val_loss: 1.1902 - val_accuracy: 0.5381\n",
      "Epoch 5/10\n",
      "2078/2078 [==============================] - 168s 81ms/step - loss: 1.3265 - accuracy: 0.4645 - val_loss: 1.4044 - val_accuracy: 0.3902\n",
      "Epoch 6/10\n",
      "2078/2078 [==============================] - 172s 83ms/step - loss: 1.3855 - accuracy: 0.4147 - val_loss: 1.3164 - val_accuracy: 0.4788\n",
      "Epoch 7/10\n",
      "2078/2078 [==============================] - 168s 81ms/step - loss: 1.2989 - accuracy: 0.4855 - val_loss: 1.3154 - val_accuracy: 0.4779\n",
      "Epoch 8/10\n",
      "2078/2078 [==============================] - 164s 79ms/step - loss: 1.2982 - accuracy: 0.4852 - val_loss: 1.3158 - val_accuracy: 0.4783\n",
      "Epoch 9/10\n",
      "2078/2078 [==============================] - 151s 72ms/step - loss: 1.2980 - accuracy: 0.4856 - val_loss: 1.3164 - val_accuracy: 0.4728\n",
      "Epoch 10/10\n",
      "2078/2078 [==============================] - 153s 73ms/step - loss: 1.3527 - accuracy: 0.4624 - val_loss: 1.3998 - val_accuracy: 0.4395\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_padded_sequences, train_labels, epochs=10, batch_size=64,\n",
    "                    validation_data=(test_padded_sequences,test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kf703A4O4z1p",
   "metadata": {
    "id": "kf703A4O4z1p"
   },
   "source": [
    "## Evalution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c1fddc65",
   "metadata": {
    "id": "c1fddc65"
   },
   "outputs": [],
   "source": [
    "save_model(model, './rnn','DL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0539e517",
   "metadata": {
    "id": "0539e517"
   },
   "outputs": [],
   "source": [
    "loaded_model =load_model('./rnn','DL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "df933c9a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "df933c9a",
    "outputId": "b7216602-1700-473c-9d5e-37c6c7b0c5d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "462/462 [==============================] - 4s 8ms/step - loss: 1.3998 - accuracy: 0.4395\n",
      "462/462 [==============================] - 4s 9ms/step\n",
      "Accuracy: 0.4395180344581604\n",
      "F1 macro: 0.20083966406445555\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.93      0.61      5764\n",
      "           1       0.37      0.41      0.39      2762\n",
      "           2       0.00      0.00      0.00      3650\n",
      "           3       0.00      0.00      0.00      1154\n",
      "           4       0.00      0.00      0.00      1443\n",
      "\n",
      "    accuracy                           0.44     14773\n",
      "   macro avg       0.17      0.27      0.20     14773\n",
      "weighted avg       0.25      0.44      0.31     14773\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "accuracy, f1_macro, report = evaluate_model(loaded_model, test_padded_sequences, test_labels,'DL')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Lt1FX6sZ43Gu",
   "metadata": {
    "id": "Lt1FX6sZ43Gu"
   },
   "source": [
    "## LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1e089dec",
   "metadata": {
    "id": "1e089dec"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Bidirectional,LSTM\n",
    "\n",
    "embedding_dim = 64\n",
    "lstm_units = 64\n",
    "\n",
    "# Define model architecture\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_seq_length))\n",
    "model.add(Bidirectional(LSTM(units=lstm_units)))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(units=5, activation='sigmoid'))\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "51074671",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "51074671",
    "outputId": "592a39f1-5034-4ace-af59-e0db70df4c96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2078/2078 [==============================] - 68s 30ms/step - loss: 0.2328 - accuracy: 0.7418 - val_loss: 0.1832 - val_accuracy: 0.8027\n",
      "Epoch 2/10\n",
      "2078/2078 [==============================] - 24s 12ms/step - loss: 0.1614 - accuracy: 0.8297 - val_loss: 0.1812 - val_accuracy: 0.8066\n",
      "Epoch 3/10\n",
      "2078/2078 [==============================] - 22s 11ms/step - loss: 0.1464 - accuracy: 0.8457 - val_loss: 0.1830 - val_accuracy: 0.8069\n",
      "Epoch 4/10\n",
      "2078/2078 [==============================] - 24s 11ms/step - loss: 0.1345 - accuracy: 0.8587 - val_loss: 0.1862 - val_accuracy: 0.8032\n",
      "Epoch 5/10\n",
      "2078/2078 [==============================] - 21s 10ms/step - loss: 0.1231 - accuracy: 0.8697 - val_loss: 0.1971 - val_accuracy: 0.7965\n",
      "Epoch 6/10\n",
      "2078/2078 [==============================] - 23s 11ms/step - loss: 0.1123 - accuracy: 0.8824 - val_loss: 0.2101 - val_accuracy: 0.7968\n",
      "Epoch 7/10\n",
      "2078/2078 [==============================] - 23s 11ms/step - loss: 0.1023 - accuracy: 0.8927 - val_loss: 0.2317 - val_accuracy: 0.7936\n",
      "Epoch 8/10\n",
      "2078/2078 [==============================] - 23s 11ms/step - loss: 0.0934 - accuracy: 0.9019 - val_loss: 0.2495 - val_accuracy: 0.7870\n",
      "Epoch 9/10\n",
      "2078/2078 [==============================] - 22s 11ms/step - loss: 0.0857 - accuracy: 0.9093 - val_loss: 0.2657 - val_accuracy: 0.7889\n",
      "Epoch 10/10\n",
      "2078/2078 [==============================] - 22s 10ms/step - loss: 0.0777 - accuracy: 0.9172 - val_loss: 0.2927 - val_accuracy: 0.7867\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_padded_sequences, train_labels, epochs=10, batch_size=64,\n",
    "                    validation_data=(test_padded_sequences,test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jOzSgVo545-H",
   "metadata": {
    "id": "jOzSgVo545-H"
   },
   "source": [
    "## Evalution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b4814a09",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b4814a09",
    "outputId": "b097e6d8-0424-4721-e277-dd8026e5f730",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "462/462 [==============================] - 2s 5ms/step - loss: 0.2927 - accuracy: 0.7867\n",
      "462/462 [==============================] - 3s 4ms/step\n",
      "Accuracy: 0.786705493927002\n",
      "F1 macro: 0.746936223754875\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.87      0.85      5764\n",
      "           1       0.80      0.81      0.80      2762\n",
      "           2       0.75      0.76      0.76      3650\n",
      "           3       0.73      0.64      0.68      1154\n",
      "           4       0.68      0.61      0.64      1443\n",
      "\n",
      "    accuracy                           0.79     14773\n",
      "   macro avg       0.76      0.74      0.75     14773\n",
      "weighted avg       0.78      0.79      0.79     14773\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy, f1_macro, report = evaluate_model(model, test_padded_sequences, test_labels,'DL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "OOSeQtdLJ6V6",
   "metadata": {
    "id": "OOSeQtdLJ6V6"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
