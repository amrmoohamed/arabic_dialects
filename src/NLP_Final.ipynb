{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "JBU3cdpk17W1",
   "metadata": {
    "id": "JBU3cdpk17W1"
   },
   "source": [
    "## Retrieve data from sqllite db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fddb98",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f6fddb98",
    "outputId": "987a4e64-898b-4070-ce61-80c576143ad0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-4db6eaca-cbc8-4ca1-b4e6-941612984ad5\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>dialect</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@toha_Altomy @gy_yah Ù‚Ù„ÙŠÙ„ÙŠÙ† Ø§Ø¯Ø¨ ÙˆÙ…Ù†Ø§ÙÙ‚ÙŠÙ†. Ù„Ùˆ Ø§...</td>\n",
       "      <td>LY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@AlmFaisal ğŸ˜‚ğŸ˜‚ Ø§Ù„Ù„ÙŠØ¨ÙŠÙŠÙ† Ù…ØªÙ‚Ù„Ø¨ÙŠÙ†!!!\\nØ¨Ø³ Ø¨Ø§Ù„Ù†Ø³Ø¨Ø© ...</td>\n",
       "      <td>LY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@smsm071990 @ALMOGRBE ÙƒÙ„ 20 ØªØ§Ù†ÙŠÙ‡ Ø´Ø§Ø¨ Ù„ÙŠØ¨ÙŠ Ø¨ÙŠØ±...</td>\n",
       "      <td>LY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@AboryPro @lyranoo85 Ø±Ø§Ù†ÙŠØ§ Ø¹Ù‚Ù„ÙŠØªÙƒ Ù…ØªØ®Ù„ÙØ©. Ø§ÙˆÙ„Ø§...</td>\n",
       "      <td>LY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@lyranoo85 Ø´ÙƒÙ„Ùƒ Ù…ØªØ¹Ù‚Ø¯Ø© Ø¹Ù„Ø´Ø§Ù† Ø§Ù„Ø±Ø§Ø¬Ù„ Ù„ÙŠ ØªØ­Ø¨ÙŠÙ‡ Ø§...</td>\n",
       "      <td>LY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4db6eaca-cbc8-4ca1-b4e6-941612984ad5')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-4db6eaca-cbc8-4ca1-b4e6-941612984ad5 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-4db6eaca-cbc8-4ca1-b4e6-941612984ad5');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                               tweet dialect\n",
       "0  @toha_Altomy @gy_yah Ù‚Ù„ÙŠÙ„ÙŠÙ† Ø§Ø¯Ø¨ ÙˆÙ…Ù†Ø§ÙÙ‚ÙŠÙ†. Ù„Ùˆ Ø§...      LY\n",
       "1  @AlmFaisal ğŸ˜‚ğŸ˜‚ Ø§Ù„Ù„ÙŠØ¨ÙŠÙŠÙ† Ù…ØªÙ‚Ù„Ø¨ÙŠÙ†!!!\\nØ¨Ø³ Ø¨Ø§Ù„Ù†Ø³Ø¨Ø© ...      LY\n",
       "2  @smsm071990 @ALMOGRBE ÙƒÙ„ 20 ØªØ§Ù†ÙŠÙ‡ Ø´Ø§Ø¨ Ù„ÙŠØ¨ÙŠ Ø¨ÙŠØ±...      LY\n",
       "3  @AboryPro @lyranoo85 Ø±Ø§Ù†ÙŠØ§ Ø¹Ù‚Ù„ÙŠØªÙƒ Ù…ØªØ®Ù„ÙØ©. Ø§ÙˆÙ„Ø§...      LY\n",
       "4  @lyranoo85 Ø´ÙƒÙ„Ùƒ Ù…ØªØ¹Ù‚Ø¯Ø© Ø¹Ù„Ø´Ø§Ù† Ø§Ù„Ø±Ø§Ø¬Ù„ Ù„ÙŠ ØªØ­Ø¨ÙŠÙ‡ Ø§...      LY"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "conn = sqlite3.connect('./Data/dialects_database.db')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "cursor.execute(\"SELECT * FROM id_text\")\n",
    "text = cursor.fetchall()\n",
    "text_df = pd.DataFrame(text, columns=['id', 'tweet'])\n",
    "\n",
    "cursor.execute(\"SELECT * FROM id_dialect\")\n",
    "dialect = cursor.fetchall()\n",
    "dialect_df = pd.DataFrame(dialect, columns=['id', 'dialect'])\n",
    "\n",
    "cursor.close()\n",
    "conn.close()\n",
    "\n",
    "df = pd.merge(text_df, dialect_df, on=\"id\")\n",
    "df.drop(['id'], axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ZRjGKeXk3PBz",
   "metadata": {
    "id": "ZRjGKeXk3PBz"
   },
   "source": [
    "## Data prepration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e009e3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "91e009e3",
    "outputId": "ccfd6ba0-ef99-45bc-87ee-3ab475708349"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicates: 0\n"
     ]
    }
   ],
   "source": [
    "num_duplicates = df.duplicated().sum()\n",
    "print('Number of duplicates:', num_duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b384448",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5b384448",
    "outputId": "bc811c2c-8825-472e-cda3-d30a34e78a47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class counts:\n",
      "EG    57636\n",
      "LY    36499\n",
      "LB    27617\n",
      "SD    14434\n",
      "MA    11539\n",
      "Name: dialect, dtype: int64\n",
      "Class proportions:\n",
      "EG    0.390157\n",
      "LY    0.247074\n",
      "LB    0.186949\n",
      "SD    0.097709\n",
      "MA    0.078111\n",
      "Name: dialect, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "class_counts = df['dialect'].value_counts()\n",
    "class_proportions = df['dialect'].value_counts(normalize=True)\n",
    "\n",
    "print('Class counts:')\n",
    "print(class_counts)\n",
    "\n",
    "print('Class proportions:')\n",
    "print(class_proportions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Kau33sKv3W3h",
   "metadata": {
    "id": "Kau33sKv3W3h"
   },
   "source": [
    "## Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2812f9ba",
   "metadata": {
    "id": "2812f9ba"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "def tokenize_tweet(tweet):\n",
    "    # create a TweetTokenizer object\n",
    "    tknzr = TweetTokenizer()\n",
    "    # tokenize the tweet\n",
    "    tokens = tknzr.tokenize(tweet)\n",
    "    return tokens\n",
    "tokenized = tokenize_tweet(df['tweet'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d09a251",
   "metadata": {
    "id": "4d09a251"
   },
   "outputs": [],
   "source": [
    "def remove_extra_spaces(words):\n",
    "    \"\"\"Removes extra whitespaces at the beginning and at the end of each word in a list\"\"\"\n",
    "    cleaned_words = []\n",
    "    for word in words:\n",
    "        cleaned_word = ' '.join(word.split()).strip()\n",
    "        cleaned_words.append(cleaned_word)\n",
    "    return cleaned_words\n",
    "r_e_s = remove_extra_spaces(tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acdac67",
   "metadata": {
    "id": "0acdac67"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def remove_urls(lst):\n",
    "    pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return [re.sub(pattern, '', item).strip() for item in lst if re.sub(pattern, '', item).strip() != '']\n",
    "r_urls = remove_urls(r_e_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e7251d",
   "metadata": {
    "id": "19e7251d"
   },
   "outputs": [],
   "source": [
    "def remove_user_mentions(words):\n",
    "    \"\"\"Removes user mentions (@user) from a list of words\"\"\"\n",
    "    cleaned_words = []\n",
    "    for word in words:\n",
    "        if not word.startswith('@'):\n",
    "            cleaned_words.append(word)\n",
    "    return cleaned_words\n",
    "r_u_m = remove_user_mentions(r_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bd37cd",
   "metadata": {
    "id": "e3bd37cd"
   },
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def remove_punctuation(lst):\n",
    "    \"\"\"Removes punctuation from a list of strings, including single punctuation characters\"\"\"\n",
    "    translator = str.maketrans('', '', string.punctuation+'ØŸ')\n",
    "    result = []\n",
    "    for item in lst:\n",
    "        # Remove all punctuation characters\n",
    "        item = item.translate(translator)\n",
    "        # Remove any remaining single punctuation characters\n",
    "        if item != '':\n",
    "          result.append(item)\n",
    "    return result\n",
    "r_p = remove_punctuation(r_u_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757f779c",
   "metadata": {
    "id": "757f779c"
   },
   "outputs": [],
   "source": [
    "def remove_numbers(lst):\n",
    "    \"\"\"Removes numbers from a list of strings\"\"\"\n",
    "    pattern = re.compile(r'\\d+')\n",
    "    return [re.sub(pattern, '', item) for item in lst if re.sub(pattern, '', item).strip() != '']\n",
    "r_n = remove_numbers(r_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51402811",
   "metadata": {
    "id": "51402811"
   },
   "outputs": [],
   "source": [
    "import emoji\n",
    "def remove_emojis(words):\n",
    "    \"\"\"Removes emojis from a list of words\"\"\"\n",
    "    cleaned_words = []\n",
    "    for word in words:\n",
    "        cleaned_word = ''.join(c for c in word if c not in emoji.EMOJI_DATA)\n",
    "        if cleaned_word != '':\n",
    "            cleaned_words.append(cleaned_word)\n",
    "    return cleaned_words\n",
    "r_e = remove_emojis(r_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50d70fd",
   "metadata": {
    "id": "f50d70fd"
   },
   "outputs": [],
   "source": [
    "def remove_foreign_language(lst):\n",
    "    pattern = re.compile(r'[^\\u0600-\\u06ff]+')\n",
    "    return [re.sub(pattern, \"\", item) for item in lst if re.sub(pattern, \"\", item) != '']\n",
    "\n",
    "r_f_l = remove_foreign_language(r_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7701792",
   "metadata": {
    "id": "f7701792"
   },
   "outputs": [],
   "source": [
    "from pyarabic.araby import strip_tashkeel\n",
    "from pyarabic.araby import normalize_ligature\n",
    "def remove_tashkeel(lst):\n",
    "    return [normalize_ligature(strip_tashkeel(word)) for word in lst]\n",
    "r_t = remove_tashkeel(r_f_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5edb36e6",
   "metadata": {
    "id": "5edb36e6"
   },
   "outputs": [],
   "source": [
    "def remove_repeated_chars(lst):\n",
    "    pattern = re.compile(r\"(\\w)\\1{2,}\")\n",
    "    return [re.sub(pattern, r\"\\1\\1\", item).strip() for item in lst if re.sub(pattern, '', item).strip() != '']\n",
    "\n",
    "r_r_c = remove_repeated_chars(r_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d897df30",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d897df30",
    "outputId": "902b80ae-675c-474d-b92e-f5ed3002ae35"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c011ddb9",
   "metadata": {
    "id": "c011ddb9"
   },
   "outputs": [],
   "source": [
    "STOP_WORDS = set(nltk.corpus.stopwords.words(\"arabic\"))\n",
    "\n",
    "def remove_stop_words(lst):\n",
    "    result = []\n",
    "    for word in lst:\n",
    "        if word not in STOP_WORDS:\n",
    "            result.append(word)\n",
    "    return result\n",
    "r_s_w = remove_stop_words(r_r_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af48ba68",
   "metadata": {
    "id": "af48ba68"
   },
   "outputs": [],
   "source": [
    "def form_sentence(words):\n",
    "    \"\"\"Forms a sentence from a list of words\"\"\"\n",
    "    sentence = ' '.join(words)\n",
    "    return sentence\n",
    "f_s = form_sentence(r_s_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5634c00",
   "metadata": {
    "id": "d5634c00"
   },
   "outputs": [],
   "source": [
    "def clean_tweet(tweet,mode=\"ml\"):\n",
    "    \"\"\"\n",
    "    A function to clean a single tweet.\n",
    "    \"\"\"\n",
    "    if mode==\"ml\":\n",
    "        #tokenize tweet \n",
    "        words = tokenize_tweet(tweet)\n",
    "        #remove extra white-spaces\n",
    "        words = remove_extra_spaces(words)\n",
    "        #remove urls \n",
    "        words = remove_urls(words)\n",
    "        #remove user mentions \n",
    "        words = remove_user_mentions(words)\n",
    "        #remove punctiation\n",
    "        words = remove_punctuation(words)\n",
    "        #remove numbers\n",
    "        words = remove_numbers(words)\n",
    "        #remove emojis\n",
    "        words = remove_emojis(words)\n",
    "        #remove non-arabic charachters\n",
    "        words = remove_foreign_language(words)\n",
    "        #remove tashkeel \n",
    "        words = remove_tashkeel(words)\n",
    "        #remove repeated charachters\n",
    "        words = remove_repeated_chars(words)\n",
    "        #remove stop words \n",
    "        words = remove_stop_words(words)\n",
    "        #form a new sentence\n",
    "        sentence = form_sentence(words)\n",
    "    else:\n",
    "        words = tokenize_tweet(tweet)\n",
    "        #remove extra white-spaces\n",
    "        words = remove_extra_spaces(words)\n",
    "        #remove urls \n",
    "        words = remove_urls(words)\n",
    "        #remove user mentions \n",
    "        words = remove_user_mentions(words)\n",
    "        #remove punctiation\n",
    "        words = remove_punctuation(words)\n",
    "        #remove numbers\n",
    "        words = remove_numbers(words)\n",
    "        #remove emojis\n",
    "        words = remove_emojis(words)\n",
    "        #remove non-arabic charachters\n",
    "        words = remove_foreign_language(words)\n",
    "        #form a new sentence\n",
    "        sentence = form_sentence(words)\n",
    "    return sentence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b348cb89",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 381
    },
    "id": "b348cb89",
    "outputId": "ae84aba3-5de8-41c7-a382-c76a959f29b2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 147725/147725 [00:00<00:00, 2335139.42it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-39c1c80a-e315-485d-90e2-424f67f43944\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>dialect</th>\n",
       "      <th>clean_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@toha_Altomy @gy_yah Ù‚Ù„ÙŠÙ„ÙŠÙ† Ø§Ø¯Ø¨ ÙˆÙ…Ù†Ø§ÙÙ‚ÙŠÙ†. Ù„Ùˆ Ø§...</td>\n",
       "      <td>LY</td>\n",
       "      <td>Ù‚Ù„ÙŠÙ„ÙŠÙ† Ø§Ø¯Ø¨ ÙˆÙ…Ù†Ø§ÙÙ‚ÙŠÙ† Ø§Ø®ØªÙ‡Ù… Ø§Ùˆ Ù‚Ø±ÙŠØ¨ØªÙ‡Ù… ØªØªØ¹Ø§ÙƒØ³ ØªÙ‚...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@AlmFaisal ğŸ˜‚ğŸ˜‚ Ø§Ù„Ù„ÙŠØ¨ÙŠÙŠÙ† Ù…ØªÙ‚Ù„Ø¨ÙŠÙ†!!!\\nØ¨Ø³ Ø¨Ø§Ù„Ù†Ø³Ø¨Ø© ...</td>\n",
       "      <td>LY</td>\n",
       "      <td>Ø§Ù„Ù„ÙŠØ¨ÙŠÙŠÙ† Ù…ØªÙ‚Ù„Ø¨ÙŠÙ† Ø¨Ø§Ù„Ù†Ø³Ø¨Ø© Ù„ÙŠØ§ Ø§Ù†Ø§ Ù…ÙŠÙ„ÙŠØ´ÙŠØ§ÙˆÙŠ Ø²Ù…Ø§...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@smsm071990 @ALMOGRBE ÙƒÙ„ 20 ØªØ§Ù†ÙŠÙ‡ Ø´Ø§Ø¨ Ù„ÙŠØ¨ÙŠ Ø¨ÙŠØ±...</td>\n",
       "      <td>LY</td>\n",
       "      <td>ØªØ§Ù†ÙŠÙ‡ Ø´Ø§Ø¨ Ù„ÙŠØ¨ÙŠ Ø¨ÙŠØ±ØªØ§Ø­ Ù„Ø¨Ù†Øª Ù…Ø®ØªÙ„ÙØ© ÙˆÙŠÙ„Ø§Ø­Ø¸ Ø§Ù†Ù‡Ø§ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@AboryPro @lyranoo85 Ø±Ø§Ù†ÙŠØ§ Ø¹Ù‚Ù„ÙŠØªÙƒ Ù…ØªØ®Ù„ÙØ©. Ø§ÙˆÙ„Ø§...</td>\n",
       "      <td>LY</td>\n",
       "      <td>Ø±Ø§Ù†ÙŠØ§ Ø¹Ù‚Ù„ÙŠØªÙƒ Ù…ØªØ®Ù„ÙØ© Ø§ÙˆÙ„Ø§ Ø§Ù„Ø§Ù†Ø³Ø§Ù† ÙŠÙ„ÙŠ ÙŠØ­ØªØ§Ø¬ Ø§Ù‡Ù„...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@lyranoo85 Ø´ÙƒÙ„Ùƒ Ù…ØªØ¹Ù‚Ø¯Ø© Ø¹Ù„Ø´Ø§Ù† Ø§Ù„Ø±Ø§Ø¬Ù„ Ù„ÙŠ ØªØ­Ø¨ÙŠÙ‡ Ø§...</td>\n",
       "      <td>LY</td>\n",
       "      <td>Ø´ÙƒÙ„Ùƒ Ù…ØªØ¹Ù‚Ø¯Ø© Ø¹Ù„Ø´Ø§Ù† Ø§Ù„Ø±Ø§Ø¬Ù„ ØªØ­Ø¨ÙŠÙ‡ Ø§Ø²ÙˆØ¬ Ø¨Ù†Øª ÙŠØªÙŠÙ…Ø© ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>@alibobkr63 Ø§Ùˆ Ø­ØªÙ‰ Ù…Ù† Ø§ÙŠ Ø¯ÙŠÙ† Ø§Ùˆ Ø·Ø§Ø¦ÙØ©. Ø§Ø³Ù Ù…Ù…Ùƒ...</td>\n",
       "      <td>LY</td>\n",
       "      <td>Ø§Ùˆ Ø§ÙŠ Ø¯ÙŠÙ† Ø§Ùˆ Ø·Ø§Ø¦ÙØ© Ø§Ø³Ù Ù…Ù…ÙƒÙ† Ø§Ù„ØºÙ„Ø· ØºÙ„Ø·ØªÙŠ Ù…ÙƒÙ†Ø´ Ù‚ØµØ¯ÙŠ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>@muhamed01111 Ø¨Ø§Ù‡ÙŠ Ù†Ø³ØªÙ†ÙˆÙ‡. Ø¨Ù„ÙƒÙŠ Ù…Ø´ØºÙˆÙ„ ÙˆÙ„Ø§ Ø­Ø§Ø¬Ø©</td>\n",
       "      <td>LY</td>\n",
       "      <td>Ø¨Ø§Ù‡ÙŠ Ù†Ø³ØªÙ†ÙˆÙ‡ Ø¨Ù„ÙƒÙŠ Ù…Ø´ØºÙˆÙ„ Ø­Ø§Ø¬Ø©</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>@muhamed01111 Ù…Ù‡Ù…Ø§ Ø§Ø®ØªÙ„ÙÙ†Ø§ Ø±Ø§Ù‡ Ù†Ø­Ù†Ø§ Ø®ÙˆØª. ÙˆØ§Ù„Ù„Ù‡...</td>\n",
       "      <td>LY</td>\n",
       "      <td>Ø§Ø®ØªÙ„ÙÙ†Ø§ Ø±Ø§Ù‡ Ù†Ø­Ù†Ø§ Ø®ÙˆØª ÙˆØ§Ù„Ù„Ù‡ Ø¹Ù†Ø¯ÙŠ Ø§Ù†Ø§ ÙØ±Ø­Ø§Ù† Ù†Ù‚Ø¯Ø±...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>@muhamed01111 Ø¨Ø§Ù„Ù†Ø³Ø¨Ø© Ù„ÙŠØ§ Ø§Ù†Ø§ ÙˆØ§Ù„Ù„Ù‡ Ø´Ø¨Ø¹Øª Ù‡Ù… ÙˆÙ†...</td>\n",
       "      <td>LY</td>\n",
       "      <td>Ø¨Ø§Ù„Ù†Ø³Ø¨Ø© Ù„ÙŠØ§ Ø§Ù†Ø§ ÙˆØ§Ù„Ù„Ù‡ Ø´Ø¨Ø¹Øª ÙˆÙ†ÙƒØ¯ ÙˆÙ‚ØªÙ„ ÙˆØ¯Ù… ÙˆØ§Ù„Ø­Ù‚...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>@Ajo32asLibya @Jed_ly Ù…Ùˆ Ù†Ø­Ù†Ø§ Ø§Ù„Ø­ÙŠØ§Ø© Ø¹Ù†Ø¯Ù†Ø§ Ù…ÙŠØ©...</td>\n",
       "      <td>LY</td>\n",
       "      <td>Ù…Ùˆ Ù†Ø­Ù†Ø§ Ø§Ù„Ø­ÙŠØ§Ø© Ø¹Ù†Ø¯Ù†Ø§ Ù…ÙŠØ© Ù…ÙŠØ© ÙˆÙ…Ø¹Ù†Ø¯Ø´ Ø´ÙŠ Ø§Ù†Ø¯ÙƒÙˆØ§ ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-39c1c80a-e315-485d-90e2-424f67f43944')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-39c1c80a-e315-485d-90e2-424f67f43944 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-39c1c80a-e315-485d-90e2-424f67f43944');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                               tweet dialect  \\\n",
       "0  @toha_Altomy @gy_yah Ù‚Ù„ÙŠÙ„ÙŠÙ† Ø§Ø¯Ø¨ ÙˆÙ…Ù†Ø§ÙÙ‚ÙŠÙ†. Ù„Ùˆ Ø§...      LY   \n",
       "1  @AlmFaisal ğŸ˜‚ğŸ˜‚ Ø§Ù„Ù„ÙŠØ¨ÙŠÙŠÙ† Ù…ØªÙ‚Ù„Ø¨ÙŠÙ†!!!\\nØ¨Ø³ Ø¨Ø§Ù„Ù†Ø³Ø¨Ø© ...      LY   \n",
       "2  @smsm071990 @ALMOGRBE ÙƒÙ„ 20 ØªØ§Ù†ÙŠÙ‡ Ø´Ø§Ø¨ Ù„ÙŠØ¨ÙŠ Ø¨ÙŠØ±...      LY   \n",
       "3  @AboryPro @lyranoo85 Ø±Ø§Ù†ÙŠØ§ Ø¹Ù‚Ù„ÙŠØªÙƒ Ù…ØªØ®Ù„ÙØ©. Ø§ÙˆÙ„Ø§...      LY   \n",
       "4  @lyranoo85 Ø´ÙƒÙ„Ùƒ Ù…ØªØ¹Ù‚Ø¯Ø© Ø¹Ù„Ø´Ø§Ù† Ø§Ù„Ø±Ø§Ø¬Ù„ Ù„ÙŠ ØªØ­Ø¨ÙŠÙ‡ Ø§...      LY   \n",
       "5  @alibobkr63 Ø§Ùˆ Ø­ØªÙ‰ Ù…Ù† Ø§ÙŠ Ø¯ÙŠÙ† Ø§Ùˆ Ø·Ø§Ø¦ÙØ©. Ø§Ø³Ù Ù…Ù…Ùƒ...      LY   \n",
       "6     @muhamed01111 Ø¨Ø§Ù‡ÙŠ Ù†Ø³ØªÙ†ÙˆÙ‡. Ø¨Ù„ÙƒÙŠ Ù…Ø´ØºÙˆÙ„ ÙˆÙ„Ø§ Ø­Ø§Ø¬Ø©      LY   \n",
       "7  @muhamed01111 Ù…Ù‡Ù…Ø§ Ø§Ø®ØªÙ„ÙÙ†Ø§ Ø±Ø§Ù‡ Ù†Ø­Ù†Ø§ Ø®ÙˆØª. ÙˆØ§Ù„Ù„Ù‡...      LY   \n",
       "8  @muhamed01111 Ø¨Ø§Ù„Ù†Ø³Ø¨Ø© Ù„ÙŠØ§ Ø§Ù†Ø§ ÙˆØ§Ù„Ù„Ù‡ Ø´Ø¨Ø¹Øª Ù‡Ù… ÙˆÙ†...      LY   \n",
       "9  @Ajo32asLibya @Jed_ly Ù…Ùˆ Ù†Ø­Ù†Ø§ Ø§Ù„Ø­ÙŠØ§Ø© Ø¹Ù†Ø¯Ù†Ø§ Ù…ÙŠØ©...      LY   \n",
       "\n",
       "                                         clean_tweet  \n",
       "0  Ù‚Ù„ÙŠÙ„ÙŠÙ† Ø§Ø¯Ø¨ ÙˆÙ…Ù†Ø§ÙÙ‚ÙŠÙ† Ø§Ø®ØªÙ‡Ù… Ø§Ùˆ Ù‚Ø±ÙŠØ¨ØªÙ‡Ù… ØªØªØ¹Ø§ÙƒØ³ ØªÙ‚...  \n",
       "1  Ø§Ù„Ù„ÙŠØ¨ÙŠÙŠÙ† Ù…ØªÙ‚Ù„Ø¨ÙŠÙ† Ø¨Ø§Ù„Ù†Ø³Ø¨Ø© Ù„ÙŠØ§ Ø§Ù†Ø§ Ù…ÙŠÙ„ÙŠØ´ÙŠØ§ÙˆÙŠ Ø²Ù…Ø§...  \n",
       "2  ØªØ§Ù†ÙŠÙ‡ Ø´Ø§Ø¨ Ù„ÙŠØ¨ÙŠ Ø¨ÙŠØ±ØªØ§Ø­ Ù„Ø¨Ù†Øª Ù…Ø®ØªÙ„ÙØ© ÙˆÙŠÙ„Ø§Ø­Ø¸ Ø§Ù†Ù‡Ø§ ...  \n",
       "3  Ø±Ø§Ù†ÙŠØ§ Ø¹Ù‚Ù„ÙŠØªÙƒ Ù…ØªØ®Ù„ÙØ© Ø§ÙˆÙ„Ø§ Ø§Ù„Ø§Ù†Ø³Ø§Ù† ÙŠÙ„ÙŠ ÙŠØ­ØªØ§Ø¬ Ø§Ù‡Ù„...  \n",
       "4  Ø´ÙƒÙ„Ùƒ Ù…ØªØ¹Ù‚Ø¯Ø© Ø¹Ù„Ø´Ø§Ù† Ø§Ù„Ø±Ø§Ø¬Ù„ ØªØ­Ø¨ÙŠÙ‡ Ø§Ø²ÙˆØ¬ Ø¨Ù†Øª ÙŠØªÙŠÙ…Ø© ...  \n",
       "5  Ø§Ùˆ Ø§ÙŠ Ø¯ÙŠÙ† Ø§Ùˆ Ø·Ø§Ø¦ÙØ© Ø§Ø³Ù Ù…Ù…ÙƒÙ† Ø§Ù„ØºÙ„Ø· ØºÙ„Ø·ØªÙŠ Ù…ÙƒÙ†Ø´ Ù‚ØµØ¯ÙŠ  \n",
       "6                        Ø¨Ø§Ù‡ÙŠ Ù†Ø³ØªÙ†ÙˆÙ‡ Ø¨Ù„ÙƒÙŠ Ù…Ø´ØºÙˆÙ„ Ø­Ø§Ø¬Ø©  \n",
       "7  Ø§Ø®ØªÙ„ÙÙ†Ø§ Ø±Ø§Ù‡ Ù†Ø­Ù†Ø§ Ø®ÙˆØª ÙˆØ§Ù„Ù„Ù‡ Ø¹Ù†Ø¯ÙŠ Ø§Ù†Ø§ ÙØ±Ø­Ø§Ù† Ù†Ù‚Ø¯Ø±...  \n",
       "8  Ø¨Ø§Ù„Ù†Ø³Ø¨Ø© Ù„ÙŠØ§ Ø§Ù†Ø§ ÙˆØ§Ù„Ù„Ù‡ Ø´Ø¨Ø¹Øª ÙˆÙ†ÙƒØ¯ ÙˆÙ‚ØªÙ„ ÙˆØ¯Ù… ÙˆØ§Ù„Ø­Ù‚...  \n",
       "9  Ù…Ùˆ Ù†Ø­Ù†Ø§ Ø§Ù„Ø­ÙŠØ§Ø© Ø¹Ù†Ø¯Ù†Ø§ Ù…ÙŠØ© Ù…ÙŠØ© ÙˆÙ…Ø¹Ù†Ø¯Ø´ Ø´ÙŠ Ø§Ù†Ø¯ÙƒÙˆØ§ ...  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "df['clean_tweet'] = tqdm(df['tweet'].apply(clean_tweet,args=(\"ml\",)))\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822195d5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "822195d5",
    "outputId": "20bc5b43-d6a9-453e-84e0-ef54da5dfd95"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "\n",
    "df.clean_tweet = df.clean_tweet.replace('',np.NaN)\n",
    "print(df['clean_tweet'].isnull().values.sum())\n",
    "\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3111ec3b",
   "metadata": {
    "id": "3111ec3b"
   },
   "outputs": [],
   "source": [
    "df = df[['clean_tweet','dialect']]\n",
    "df.to_csv(\"./Data/clean_df.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "j222BOT-XDOy",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j222BOT-XDOy",
    "outputId": "a94ddd24-0147-481d-c8f5-4700b123bdcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(147652, 2)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "df = pd.read_csv('./Data/clean_df.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9202f49a",
   "metadata": {
    "id": "9202f49a"
   },
   "outputs": [],
   "source": [
    "# from ar_wordcloud import ArabicWordCloud\n",
    "\n",
    "# text = \" \".join(i for i in df.clean_tweet)\n",
    "# awc = ArabicWordCloud(background_color=\"white\")\n",
    "# awc.from_text(text).to_image()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fGcQPQLK3eUy",
   "metadata": {
    "id": "fGcQPQLK3eUy"
   },
   "source": [
    "## Train ML models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "55389a3c",
   "metadata": {
    "id": "55389a3c"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df[\"clean_tweet\"].astype('U').values.tolist()\n",
    "y = df[\"dialect\"].astype('U').values.tolist()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc167017",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "id": "bc167017",
    "outputId": "2cd88d28-d091-404e-91b8-42027c5b9c58"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TfidfVectorizer(ngram_range=(1, 3))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(ngram_range=(1, 3))</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "TfidfVectorizer(ngram_range=(1, 3))"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "corpus = X_train\n",
    "# Initizalize the vectorizer with max nr words and ngrams (1: single words, 2: two words in a row)\n",
    "vectorizer_tfidf = TfidfVectorizer(ngram_range=(1,3))\n",
    "#corpus = vectorizer_tfidf.fit_transform(corpus.apply(lambda x: np.str_(x)))\n",
    "# Fit the vectorizer to the training data\n",
    "vectorizer_tfidf.fit(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "F25lIw30fCW0",
   "metadata": {
    "id": "F25lIw30fCW0"
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "def evaluate_model(model, X_test, y_test,model_type=None):\n",
    "  \"\"\" Evaluates a model on test data\n",
    "\n",
    "  Args:\n",
    "    model: The model to evaluate.\n",
    "    test_data: The test data.\n",
    "\n",
    "  Returns:\n",
    "    The accuracy score and f1 macro score.\n",
    "\n",
    "  \"\"\"\n",
    "  if model_type == 'DL':\n",
    "        loss, accuracy = model.evaluate(X_test,y_test)\n",
    "        probabilites = model.predict(X_test)\n",
    "        predictions = probabilites.argmax(axis=-1)\n",
    "        y_test = y_test.argmax(axis=-1)\n",
    "  else:\n",
    "      # Make predictions on the test data.\n",
    "      predictions = model.predict(X_test)\n",
    "\n",
    "      # Calculate the accuracy score.\n",
    "      accuracy = accuracy_score(y_test, predictions)\n",
    "\n",
    "  # Calculate the f1 macro score.\n",
    "  f1_macro = f1_score(y_test, predictions, average=\"macro\")\n",
    "\n",
    "  # Print the results.\n",
    "  print(\"Accuracy:\", accuracy)\n",
    "  print(\"F1 macro:\", f1_macro)\n",
    "\n",
    "  report = metrics.classification_report(y_test, predictions)\n",
    "  print(report)\n",
    "\n",
    "  return accuracy, f1_macro, report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "270362be",
   "metadata": {
    "id": "270362be"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import keras\n",
    "def save_model(model, filename, mode=None):\n",
    "  \"\"\"Saves a model to a .pkl file.\n",
    "\n",
    "  Args:\n",
    "    model: The model to save.\n",
    "    filename: The name of the file to save the model to.\n",
    "\n",
    "  \"\"\"\n",
    "  if mode == 'DL':\n",
    "        model.save(filename)\n",
    "  else:\n",
    "      with open(filename, \"wb\") as f:\n",
    "        pickle.dump(model, f)\n",
    "\n",
    "def load_model(filename,mode=None):\n",
    "  \"\"\"Loads a model from a .pkl file.\n",
    "\n",
    "  Args:\n",
    "    filename: The name of the file to load the model from.\n",
    "\n",
    "  Returns:\n",
    "    The loaded model.\n",
    "\n",
    "  \"\"\"\n",
    "  if mode == 'DL':\n",
    "        model = keras.models.load_model(filename)\n",
    "  else:     \n",
    "      with open(filename, \"rb\") as f:\n",
    "        model = pickle.load(f)\n",
    "\n",
    "  return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kixyLeej4EaZ",
   "metadata": {
    "id": "kixyLeej4EaZ"
   },
   "source": [
    "## Multinomialnb Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5051c9a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "id": "e5051c9a",
    "outputId": "a574fdf7-d65d-4700-85d4-495a5043baf4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;vectorizer&#x27;, TfidfVectorizer(ngram_range=(1, 3))),\n",
       "                (&#x27;classifier&#x27;, MultinomialNB())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;vectorizer&#x27;, TfidfVectorizer(ngram_range=(1, 3))),\n",
       "                (&#x27;classifier&#x27;, MultinomialNB())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(ngram_range=(1, 3))</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('vectorizer', TfidfVectorizer(ngram_range=(1, 3))),\n",
       "                ('classifier', MultinomialNB())])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "classifier_tfidf_NB = MultinomialNB()\n",
    "model_tfidf_NB = Pipeline([(\"vectorizer\", vectorizer_tfidf), (\"classifier\", classifier_tfidf_NB)])\n",
    "\n",
    "model_tfidf_NB.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "OGqQUZwb4YSy",
   "metadata": {
    "id": "OGqQUZwb4YSy"
   },
   "source": [
    "## Evalution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Gh6Q7TWBfQi3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gh6Q7TWBfQi3",
    "outputId": "be0b3f9c-3882-4af8-c748-789ff310b507"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6653799268590004\n",
      "F1 macro: 0.5056611076652915\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          EG       0.56      1.00      0.72      5762\n",
      "          LB       0.96      0.62      0.75      2762\n",
      "          LY       0.85      0.58      0.69      3648\n",
      "          MA       1.00      0.16      0.27      1154\n",
      "          SD       1.00      0.05      0.09      1440\n",
      "\n",
      "    accuracy                           0.67     14766\n",
      "   macro avg       0.87      0.48      0.51     14766\n",
      "weighted avg       0.78      0.67      0.62     14766\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy, f1_macro, report = evaluate_model(model_tfidf_NB, X_test, y_test)\n",
    "save_model(model_tfidf_NB,'NB.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jysGEcVG4Jzy",
   "metadata": {
    "id": "jysGEcVG4Jzy"
   },
   "source": [
    "## linear SVC model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5df70a8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "id": "a5df70a8",
    "outputId": "00710af2-ee3a-4654-a1f3-b490967adf42"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;vectorizer&#x27;, TfidfVectorizer(ngram_range=(1, 3))),\n",
       "                (&#x27;classifier&#x27;, LinearSVC())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;vectorizer&#x27;, TfidfVectorizer(ngram_range=(1, 3))),\n",
       "                (&#x27;classifier&#x27;, LinearSVC())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(ngram_range=(1, 3))</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearSVC</label><div class=\"sk-toggleable__content\"><pre>LinearSVC()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('vectorizer', TfidfVectorizer(ngram_range=(1, 3))),\n",
       "                ('classifier', LinearSVC())])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from nltk.classify import SklearnClassifier\n",
    "\n",
    "classifier_tfidf_SVC = LinearSVC()\n",
    "#classifier_tfidf_SVC = SVC(kernel='linear',probability=True)\n",
    "#classifier_tfidf_SVC = SklearnClassifier(SVC(kernel='linear',probability=True))\n",
    "\n",
    "model_tfidf_SVC = Pipeline([(\"vectorizer\", vectorizer_tfidf), (\"classifier\", classifier_tfidf_SVC)])\n",
    "\n",
    "model_tfidf_SVC.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2zRpKDhI4c17",
   "metadata": {
    "id": "2zRpKDhI4c17"
   },
   "source": [
    "## Evalution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4k8J_DMKfx27",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4k8J_DMKfx27",
    "outputId": "4b20c1f5-6f0b-4a44-8eb3-e7dd7a1aaa4a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8365840444263849\n",
      "F1 macro: 0.8047681802874983\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          EG       0.83      0.93      0.88      5762\n",
      "          LB       0.86      0.86      0.86      2762\n",
      "          LY       0.83      0.81      0.82      3648\n",
      "          MA       0.87      0.68      0.77      1154\n",
      "          SD       0.82      0.62      0.70      1440\n",
      "\n",
      "    accuracy                           0.84     14766\n",
      "   macro avg       0.84      0.78      0.80     14766\n",
      "weighted avg       0.84      0.84      0.83     14766\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy, f1_macro, report = evaluate_model(model_tfidf_SVC, X_test, y_test)\n",
    "#save_model(model_tfidf_SVC,'SVC.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "SgpHuacp4ium",
   "metadata": {
    "id": "SgpHuacp4ium"
   },
   "source": [
    "## Traim DL Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3b3664",
   "metadata": {
    "id": "7e3b3664"
   },
   "outputs": [],
   "source": [
    "# one_hot_repr = to_categorical([0,1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8367c3",
   "metadata": {
    "id": "ae8367c3"
   },
   "outputs": [],
   "source": [
    "# encoder.inverse_transform([2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ZmnjiEkLtbOB",
   "metadata": {
    "id": "ZmnjiEkLtbOB"
   },
   "outputs": [],
   "source": [
    "# from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# def classify_sentence(model, sentence, model_type=None,max_seq_length=None,encoder_type=None,encoder=None):\n",
    "#   \"\"\"Classifies a sentence using a model.\n",
    "\n",
    "#   Args:\n",
    "#     model: The model to use for classification.\n",
    "#     sentence: The sentence to classify.\n",
    "\n",
    "#   Returns:\n",
    "#     A tuple of the predicted label and the predicted probabilities for each class.\n",
    "\n",
    "#   \"\"\"\n",
    "#   if model_type == 'DL' and max_seq_length != None:\n",
    "#         tokenized_tweet = tokenize_and_pad_tweet(sentence,max_seq_length)\n",
    "#         probabilities_array = model.predict(tokenized_tweet)\n",
    "#         predicted_probabilities = probabilities_array.tolist()[0]\n",
    "#         predicted_label = probabilities_array.argmax(axis=-1)\n",
    "#         one_hot_repr = (probabilities_array == probabilities_array.max(axis=1)[:,None]).astype(int)\n",
    "#         if encoder_type == 'onehot':\n",
    "#             predicted_dialect = encoder.inverse_transform(one_hot_repr)[0]\n",
    "#             print(f\"predicted Dialect is {predicted_dialect[0]} \\n\")\n",
    "#             for i in range(len(encoder.categories_[0])):\n",
    "#                 print(f\"predicted Dialect {encoder.categories_[0][i]} with probability {predicted_probabilities[i]*100} \\n\")\n",
    "#         elif encoder_type == 'label':\n",
    "#             predicted_dialect = encoder.inverse_transform([predicted_label])\n",
    "#             print(f\"predicted Dialect is {predicted_dialect[0]} \\n\")         \n",
    "#             for i in range(len(encoder.classes_)):\n",
    "#                 print(f\"predicted Dialect {encoder.classes_[i]} with probability {predicted_probabilities[i]*100} \\n\")         \n",
    "                    \n",
    "#   else:\n",
    "#       # Make a prediction.\n",
    "#       predicted_label = model.predict([sentence])\n",
    "#       print(f\"predicted Dialect is {predicted_label[0]} \\n\")\n",
    "\n",
    "#       # Get the predicted probabilities for each class.\n",
    "#       predicted_probabilities = None\n",
    "#       try:\n",
    "#         predicted_probabilities = model.predict_proba([sentence]).tolist()[0]\n",
    "#         for i in range(len(model.classes_)):\n",
    "#           print(f\"predicted Dialect {model.classes_[i]} with probability {predicted_probabilities[i]*100} \\n\")\n",
    "\n",
    "#       except AttributeError:\n",
    "#         print(\"Model doesn't support predicting probabilites\")\n",
    "\n",
    "#   return predicted_label, predicted_probabilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "512ef0a5",
   "metadata": {
    "id": "512ef0a5"
   },
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('./Data/dialects_database.db')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "cursor.execute(\"SELECT * FROM id_text\")\n",
    "text = cursor.fetchall()\n",
    "text_df = pd.DataFrame(text, columns=['id', 'tweet'])\n",
    "\n",
    "cursor.execute(\"SELECT * FROM id_dialect\")\n",
    "dialect = cursor.fetchall()\n",
    "dialect_df = pd.DataFrame(dialect, columns=['id', 'dialect'])\n",
    "\n",
    "cursor.close()\n",
    "conn.close()\n",
    "\n",
    "df = pd.merge(text_df, dialect_df, on=\"id\")\n",
    "df.drop(['id'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1c9edcae",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 381
    },
    "id": "1c9edcae",
    "outputId": "40d64d3b-d939-4bb8-b2af-b790f09354ae",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 147725/147725 [00:00<00:00, 2677734.04it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-209d690d-ce6f-443c-9a55-6268ff5ee72c\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>dialect</th>\n",
       "      <th>clean_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@toha_Altomy @gy_yah Ù‚Ù„ÙŠÙ„ÙŠÙ† Ø§Ø¯Ø¨ ÙˆÙ…Ù†Ø§ÙÙ‚ÙŠÙ†. Ù„Ùˆ Ø§...</td>\n",
       "      <td>LY</td>\n",
       "      <td>Ù‚Ù„ÙŠÙ„ÙŠÙ† Ø§Ø¯Ø¨ ÙˆÙ…Ù†Ø§ÙÙ‚ÙŠÙ† Ù„Ùˆ Ø§Ø®ØªÙ‡Ù… Ø§Ùˆ Ù‚Ø±ÙŠØ¨ØªÙ‡Ù… ØªØªØ¹Ø§ÙƒØ³...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@AlmFaisal ğŸ˜‚ğŸ˜‚ Ø§Ù„Ù„ÙŠØ¨ÙŠÙŠÙ† Ù…ØªÙ‚Ù„Ø¨ÙŠÙ†!!!\\nØ¨Ø³ Ø¨Ø§Ù„Ù†Ø³Ø¨Ø© ...</td>\n",
       "      <td>LY</td>\n",
       "      <td>Ø§Ù„Ù„ÙŠØ¨ÙŠÙŠÙ† Ù…ØªÙ‚Ù„Ø¨ÙŠÙ† Ø¨Ø³ Ø¨Ø§Ù„Ù†Ø³Ø¨Ø© Ù„ÙŠØ§ Ø§Ù†Ø§ Ù…ÙŠÙ„ÙŠØ´ÙŠØ§ÙˆÙŠ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@smsm071990 @ALMOGRBE ÙƒÙ„ 20 ØªØ§Ù†ÙŠÙ‡ Ø´Ø§Ø¨ Ù„ÙŠØ¨ÙŠ Ø¨ÙŠØ±...</td>\n",
       "      <td>LY</td>\n",
       "      <td>ÙƒÙ„ ØªØ§Ù†ÙŠÙ‡ Ø´Ø§Ø¨ Ù„ÙŠØ¨ÙŠ Ø¨ÙŠØ±ØªØ§Ø­ Ù„Ø¨Ù†Øª Ù…Ø®ØªÙ„ÙØ© ÙˆÙŠÙ„Ø§Ø­Ø¸ Ø§Ù†...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@AboryPro @lyranoo85 Ø±Ø§Ù†ÙŠØ§ Ø¹Ù‚Ù„ÙŠØªÙƒ Ù…ØªØ®Ù„ÙØ©. Ø§ÙˆÙ„Ø§...</td>\n",
       "      <td>LY</td>\n",
       "      <td>Ø±Ø§Ù†ÙŠØ§ Ø¹Ù‚Ù„ÙŠØªÙƒ Ù…ØªØ®Ù„ÙØ© Ø§ÙˆÙ„Ø§ Ø§Ù„Ø§Ù†Ø³Ø§Ù† ÙŠÙ„ÙŠ ÙŠØ­ØªØ§Ø¬ Ø§Ù‡Ù„...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@lyranoo85 Ø´ÙƒÙ„Ùƒ Ù…ØªØ¹Ù‚Ø¯Ø© Ø¹Ù„Ø´Ø§Ù† Ø§Ù„Ø±Ø§Ø¬Ù„ Ù„ÙŠ ØªØ­Ø¨ÙŠÙ‡ Ø§...</td>\n",
       "      <td>LY</td>\n",
       "      <td>Ø´ÙƒÙ„Ùƒ Ù…ØªØ¹Ù‚Ø¯Ø© Ø¹Ù„Ø´Ø§Ù† Ø§Ù„Ø±Ø§Ø¬Ù„ Ù„ÙŠ ØªØ­Ø¨ÙŠÙ‡ Ø§Ø²ÙˆØ¬ Ø¨Ù†Øª ÙŠØªÙŠ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>@alibobkr63 Ø§Ùˆ Ø­ØªÙ‰ Ù…Ù† Ø§ÙŠ Ø¯ÙŠÙ† Ø§Ùˆ Ø·Ø§Ø¦ÙØ©. Ø§Ø³Ù Ù…Ù…Ùƒ...</td>\n",
       "      <td>LY</td>\n",
       "      <td>Ø§Ùˆ Ø­ØªÙ‰ Ù…Ù† Ø§ÙŠ Ø¯ÙŠÙ† Ø§Ùˆ Ø·Ø§Ø¦ÙØ© Ø§Ø³Ù Ù…Ù…ÙƒÙ† Ø§Ù„ØºÙ„Ø· ØºÙ„Ø·ØªÙŠ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>@muhamed01111 Ø¨Ø§Ù‡ÙŠ Ù†Ø³ØªÙ†ÙˆÙ‡. Ø¨Ù„ÙƒÙŠ Ù…Ø´ØºÙˆÙ„ ÙˆÙ„Ø§ Ø­Ø§Ø¬Ø©</td>\n",
       "      <td>LY</td>\n",
       "      <td>Ø¨Ø§Ù‡ÙŠ Ù†Ø³ØªÙ†ÙˆÙ‡ Ø¨Ù„ÙƒÙŠ Ù…Ø´ØºÙˆÙ„ ÙˆÙ„Ø§ Ø­Ø§Ø¬Ø©</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>@muhamed01111 Ù…Ù‡Ù…Ø§ Ø§Ø®ØªÙ„ÙÙ†Ø§ Ø±Ø§Ù‡ Ù†Ø­Ù†Ø§ Ø®ÙˆØª. ÙˆØ§Ù„Ù„Ù‡...</td>\n",
       "      <td>LY</td>\n",
       "      <td>Ù…Ù‡Ù…Ø§ Ø§Ø®ØªÙ„ÙÙ†Ø§ Ø±Ø§Ù‡ Ù†Ø­Ù†Ø§ Ø®ÙˆØª ÙˆØ§Ù„Ù„Ù‡ Ù…Ø§ Ø¹Ù†Ø¯ÙŠ Ø¹Ø¯Ø§ Ø¹Ù„...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>@muhamed01111 Ø¨Ø§Ù„Ù†Ø³Ø¨Ø© Ù„ÙŠØ§ Ø§Ù†Ø§ ÙˆØ§Ù„Ù„Ù‡ Ø´Ø¨Ø¹Øª Ù‡Ù… ÙˆÙ†...</td>\n",
       "      <td>LY</td>\n",
       "      <td>Ø¨Ø§Ù„Ù†Ø³Ø¨Ø© Ù„ÙŠØ§ Ø§Ù†Ø§ ÙˆØ§Ù„Ù„Ù‡ Ø´Ø¨Ø¹Øª Ù‡Ù… ÙˆÙ†ÙƒØ¯ ÙˆÙ‚ØªÙ„ ÙˆØ¯Ù… ÙˆØ§...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>@Ajo32asLibya @Jed_ly Ù…Ùˆ Ù†Ø­Ù†Ø§ Ø§Ù„Ø­ÙŠØ§Ø© Ø¹Ù†Ø¯Ù†Ø§ Ù…ÙŠØ©...</td>\n",
       "      <td>LY</td>\n",
       "      <td>Ù…Ùˆ Ù†Ø­Ù†Ø§ Ø§Ù„Ø­ÙŠØ§Ø© Ø¹Ù†Ø¯Ù†Ø§ Ù…ÙŠØ© ÙÙŠ Ù…ÙŠØ© ÙˆÙ…Ø¹Ù†Ø¯Ø´ Ø´ÙŠ Ø§Ù†Ø¯Ùƒ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-209d690d-ce6f-443c-9a55-6268ff5ee72c')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-209d690d-ce6f-443c-9a55-6268ff5ee72c button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-209d690d-ce6f-443c-9a55-6268ff5ee72c');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                               tweet dialect  \\\n",
       "0  @toha_Altomy @gy_yah Ù‚Ù„ÙŠÙ„ÙŠÙ† Ø§Ø¯Ø¨ ÙˆÙ…Ù†Ø§ÙÙ‚ÙŠÙ†. Ù„Ùˆ Ø§...      LY   \n",
       "1  @AlmFaisal ğŸ˜‚ğŸ˜‚ Ø§Ù„Ù„ÙŠØ¨ÙŠÙŠÙ† Ù…ØªÙ‚Ù„Ø¨ÙŠÙ†!!!\\nØ¨Ø³ Ø¨Ø§Ù„Ù†Ø³Ø¨Ø© ...      LY   \n",
       "2  @smsm071990 @ALMOGRBE ÙƒÙ„ 20 ØªØ§Ù†ÙŠÙ‡ Ø´Ø§Ø¨ Ù„ÙŠØ¨ÙŠ Ø¨ÙŠØ±...      LY   \n",
       "3  @AboryPro @lyranoo85 Ø±Ø§Ù†ÙŠØ§ Ø¹Ù‚Ù„ÙŠØªÙƒ Ù…ØªØ®Ù„ÙØ©. Ø§ÙˆÙ„Ø§...      LY   \n",
       "4  @lyranoo85 Ø´ÙƒÙ„Ùƒ Ù…ØªØ¹Ù‚Ø¯Ø© Ø¹Ù„Ø´Ø§Ù† Ø§Ù„Ø±Ø§Ø¬Ù„ Ù„ÙŠ ØªØ­Ø¨ÙŠÙ‡ Ø§...      LY   \n",
       "5  @alibobkr63 Ø§Ùˆ Ø­ØªÙ‰ Ù…Ù† Ø§ÙŠ Ø¯ÙŠÙ† Ø§Ùˆ Ø·Ø§Ø¦ÙØ©. Ø§Ø³Ù Ù…Ù…Ùƒ...      LY   \n",
       "6     @muhamed01111 Ø¨Ø§Ù‡ÙŠ Ù†Ø³ØªÙ†ÙˆÙ‡. Ø¨Ù„ÙƒÙŠ Ù…Ø´ØºÙˆÙ„ ÙˆÙ„Ø§ Ø­Ø§Ø¬Ø©      LY   \n",
       "7  @muhamed01111 Ù…Ù‡Ù…Ø§ Ø§Ø®ØªÙ„ÙÙ†Ø§ Ø±Ø§Ù‡ Ù†Ø­Ù†Ø§ Ø®ÙˆØª. ÙˆØ§Ù„Ù„Ù‡...      LY   \n",
       "8  @muhamed01111 Ø¨Ø§Ù„Ù†Ø³Ø¨Ø© Ù„ÙŠØ§ Ø§Ù†Ø§ ÙˆØ§Ù„Ù„Ù‡ Ø´Ø¨Ø¹Øª Ù‡Ù… ÙˆÙ†...      LY   \n",
       "9  @Ajo32asLibya @Jed_ly Ù…Ùˆ Ù†Ø­Ù†Ø§ Ø§Ù„Ø­ÙŠØ§Ø© Ø¹Ù†Ø¯Ù†Ø§ Ù…ÙŠØ©...      LY   \n",
       "\n",
       "                                         clean_tweet  \n",
       "0  Ù‚Ù„ÙŠÙ„ÙŠÙ† Ø§Ø¯Ø¨ ÙˆÙ…Ù†Ø§ÙÙ‚ÙŠÙ† Ù„Ùˆ Ø§Ø®ØªÙ‡Ù… Ø§Ùˆ Ù‚Ø±ÙŠØ¨ØªÙ‡Ù… ØªØªØ¹Ø§ÙƒØ³...  \n",
       "1  Ø§Ù„Ù„ÙŠØ¨ÙŠÙŠÙ† Ù…ØªÙ‚Ù„Ø¨ÙŠÙ† Ø¨Ø³ Ø¨Ø§Ù„Ù†Ø³Ø¨Ø© Ù„ÙŠØ§ Ø§Ù†Ø§ Ù…ÙŠÙ„ÙŠØ´ÙŠØ§ÙˆÙŠ ...  \n",
       "2  ÙƒÙ„ ØªØ§Ù†ÙŠÙ‡ Ø´Ø§Ø¨ Ù„ÙŠØ¨ÙŠ Ø¨ÙŠØ±ØªØ§Ø­ Ù„Ø¨Ù†Øª Ù…Ø®ØªÙ„ÙØ© ÙˆÙŠÙ„Ø§Ø­Ø¸ Ø§Ù†...  \n",
       "3  Ø±Ø§Ù†ÙŠØ§ Ø¹Ù‚Ù„ÙŠØªÙƒ Ù…ØªØ®Ù„ÙØ© Ø§ÙˆÙ„Ø§ Ø§Ù„Ø§Ù†Ø³Ø§Ù† ÙŠÙ„ÙŠ ÙŠØ­ØªØ§Ø¬ Ø§Ù‡Ù„...  \n",
       "4  Ø´ÙƒÙ„Ùƒ Ù…ØªØ¹Ù‚Ø¯Ø© Ø¹Ù„Ø´Ø§Ù† Ø§Ù„Ø±Ø§Ø¬Ù„ Ù„ÙŠ ØªØ­Ø¨ÙŠÙ‡ Ø§Ø²ÙˆØ¬ Ø¨Ù†Øª ÙŠØªÙŠ...  \n",
       "5  Ø§Ùˆ Ø­ØªÙ‰ Ù…Ù† Ø§ÙŠ Ø¯ÙŠÙ† Ø§Ùˆ Ø·Ø§Ø¦ÙØ© Ø§Ø³Ù Ù…Ù…ÙƒÙ† Ø§Ù„ØºÙ„Ø· ØºÙ„Ø·ØªÙŠ...  \n",
       "6                    Ø¨Ø§Ù‡ÙŠ Ù†Ø³ØªÙ†ÙˆÙ‡ Ø¨Ù„ÙƒÙŠ Ù…Ø´ØºÙˆÙ„ ÙˆÙ„Ø§ Ø­Ø§Ø¬Ø©  \n",
       "7  Ù…Ù‡Ù…Ø§ Ø§Ø®ØªÙ„ÙÙ†Ø§ Ø±Ø§Ù‡ Ù†Ø­Ù†Ø§ Ø®ÙˆØª ÙˆØ§Ù„Ù„Ù‡ Ù…Ø§ Ø¹Ù†Ø¯ÙŠ Ø¹Ø¯Ø§ Ø¹Ù„...  \n",
       "8  Ø¨Ø§Ù„Ù†Ø³Ø¨Ø© Ù„ÙŠØ§ Ø§Ù†Ø§ ÙˆØ§Ù„Ù„Ù‡ Ø´Ø¨Ø¹Øª Ù‡Ù… ÙˆÙ†ÙƒØ¯ ÙˆÙ‚ØªÙ„ ÙˆØ¯Ù… ÙˆØ§...  \n",
       "9  Ù…Ùˆ Ù†Ø­Ù†Ø§ Ø§Ù„Ø­ÙŠØ§Ø© Ø¹Ù†Ø¯Ù†Ø§ Ù…ÙŠØ© ÙÙŠ Ù…ÙŠØ© ÙˆÙ…Ø¹Ù†Ø¯Ø´ Ø´ÙŠ Ø§Ù†Ø¯Ùƒ...  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['clean_tweet'] = tqdm(df['tweet'].apply(clean_tweet,args=(\"dl\",)))\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "94843f63",
   "metadata": {
    "id": "94843f63"
   },
   "outputs": [],
   "source": [
    "X = df[\"clean_tweet\"].astype('U').values.tolist()\n",
    "y = df[\"dialect\"].astype('U').values.tolist()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ksFsFrhoC_N2",
   "metadata": {
    "id": "ksFsFrhoC_N2"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import tkseem as tk\n",
    "\n",
    "\n",
    "def tokenize_and_pad_tweets(data,datatype= 'train',max_words=None,max_seq_len=None,model_path= './tokenizer_model.pkl'):\n",
    "    \"\"\"Tokenizes tweets and pads the sequences to the length of the longest sequence in the dataset.\n",
    "\n",
    "    Args:\n",
    "        df_column (pandas.Series): A DataFrame column containing tweets.\n",
    "\n",
    "    Returns:\n",
    "        tuple:\n",
    "            numpy.ndarray: An array of padded sequences.\n",
    "            int: The vocabulary size.\n",
    "            int: The maximum sequence length.\n",
    "            Tokenizer: The tokenizer object used for the tokenization.\n",
    "    \"\"\"\n",
    "    if max_words == None:\n",
    "          tokenizer = tk.WordTokenizer()\n",
    "    else:\n",
    "          tokenizer = tk.WordTokenizer(vocab_size=max_words)\n",
    "            \n",
    "    if datatype == 'train':\n",
    "        # Create tokenizer \n",
    "        path = './tokenizer.txt'\n",
    "        df = pd.DataFrame(data,columns=['tweet'])\n",
    "        df.to_csv(path, sep='\\n', header=False,index=False)\n",
    "\n",
    "        tokenizer.train(path)\n",
    "        \n",
    "        sequences = [tokenizer.encode(sentence) for sentence in data]\n",
    "        max_seq_len = max(len(seq) for seq in sequences)\n",
    "        \n",
    "        vocab_size = tokenizer.vocab_size\n",
    "        sequences = pad_sequences(sequences, maxlen=max_seq_len,value = 0, padding='post')\n",
    "         \n",
    "    \n",
    "        tokenizer.save_model('./tokenizer_model.pkl')\n",
    "    \n",
    "    elif datatype == 'test' and max_seq_len != None:\n",
    "        try:\n",
    "            tokenizer.load_model(model_path)\n",
    "            sequences = [tokenizer.encode(sentence) for sentence in data]\n",
    "            vocab_size = tokenizer.vocab_size\n",
    "            sequences = pad_sequences(sequences, maxlen=max_seq_len,value = 0, padding='post')\n",
    "            \n",
    "        except:\n",
    "            print(\"please check if tokenizer model is passed correctly!\")\n",
    "    \n",
    "    return sequences, vocab_size, max_seq_len, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "Y9bVXBlRIanc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y9bVXBlRIanc",
    "outputId": "6e449f7e-95db-469b-b6da-78d99de9dd2d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training WordTokenizer ...\n",
      "Saving as pickle file ...\n"
     ]
    }
   ],
   "source": [
    "train_padded_sequences, vocab_size, max_seq_length, tokenizer = tokenize_and_pad_tweets(X_train,'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e20e3998",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e20e3998",
    "outputId": "0cd00387-57d4-4c66-b7d5-c41f2778c47e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading as pickle file ...\n"
     ]
    }
   ],
   "source": [
    "test_padded_sequences, vocab_size, max_seq_length, tokenizer = tokenize_and_pad_tweets(X_test,'test',None,max_seq_length,'./tokenizer_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cadf761f",
   "metadata": {
    "id": "cadf761f"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder,LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "#creating instance of one-hot-encoder\n",
    "#encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "#train_labels = encoder.fit_transform(pd.DataFrame(y_train)).toarray()\n",
    "#test_labels = encoder.fit_transform(pd.DataFrame(y_test)).toarray()\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "train_labels = encoder.fit_transform(y_train)\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = encoder.transform(y_test)\n",
    "test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "TgSUSC1v4wMM",
   "metadata": {
    "id": "TgSUSC1v4wMM"
   },
   "source": [
    "## RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3defb59a",
   "metadata": {
    "id": "3defb59a"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense\n",
    "\n",
    "embedding_dim = 64\n",
    "rnn_units = 64\n",
    "# Define model architecture\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_seq_length))\n",
    "model.add(SimpleRNN(units=rnn_units))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(units=5, activation='softmax'))\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7ae96dbd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7ae96dbd",
    "outputId": "76685bc8-5a2f-4300-9566-c49b749888e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2078/2078 [==============================] - 221s 103ms/step - loss: 1.4405 - accuracy: 0.3942 - val_loss: 1.3751 - val_accuracy: 0.4321\n",
      "Epoch 2/10\n",
      "2078/2078 [==============================] - 173s 83ms/step - loss: 1.2185 - accuracy: 0.5289 - val_loss: 1.0906 - val_accuracy: 0.6016\n",
      "Epoch 3/10\n",
      "2078/2078 [==============================] - 169s 82ms/step - loss: 1.0171 - accuracy: 0.6299 - val_loss: 1.0282 - val_accuracy: 0.6242\n",
      "Epoch 4/10\n",
      "2078/2078 [==============================] - 163s 79ms/step - loss: 0.9744 - accuracy: 0.6500 - val_loss: 1.1902 - val_accuracy: 0.5381\n",
      "Epoch 5/10\n",
      "2078/2078 [==============================] - 168s 81ms/step - loss: 1.3265 - accuracy: 0.4645 - val_loss: 1.4044 - val_accuracy: 0.3902\n",
      "Epoch 6/10\n",
      "2078/2078 [==============================] - 172s 83ms/step - loss: 1.3855 - accuracy: 0.4147 - val_loss: 1.3164 - val_accuracy: 0.4788\n",
      "Epoch 7/10\n",
      "2078/2078 [==============================] - 168s 81ms/step - loss: 1.2989 - accuracy: 0.4855 - val_loss: 1.3154 - val_accuracy: 0.4779\n",
      "Epoch 8/10\n",
      "2078/2078 [==============================] - 164s 79ms/step - loss: 1.2982 - accuracy: 0.4852 - val_loss: 1.3158 - val_accuracy: 0.4783\n",
      "Epoch 9/10\n",
      "2078/2078 [==============================] - 151s 72ms/step - loss: 1.2980 - accuracy: 0.4856 - val_loss: 1.3164 - val_accuracy: 0.4728\n",
      "Epoch 10/10\n",
      "2078/2078 [==============================] - 153s 73ms/step - loss: 1.3527 - accuracy: 0.4624 - val_loss: 1.3998 - val_accuracy: 0.4395\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_padded_sequences, train_labels, epochs=10, batch_size=64,\n",
    "                    validation_data=(test_padded_sequences,test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kf703A4O4z1p",
   "metadata": {
    "id": "kf703A4O4z1p"
   },
   "source": [
    "## Evalution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c1fddc65",
   "metadata": {
    "id": "c1fddc65"
   },
   "outputs": [],
   "source": [
    "save_model(model, './rnn','DL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0539e517",
   "metadata": {
    "id": "0539e517"
   },
   "outputs": [],
   "source": [
    "loaded_model =load_model('./rnn','DL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "df933c9a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "df933c9a",
    "outputId": "b7216602-1700-473c-9d5e-37c6c7b0c5d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "462/462 [==============================] - 4s 8ms/step - loss: 1.3998 - accuracy: 0.4395\n",
      "462/462 [==============================] - 4s 9ms/step\n",
      "Accuracy: 0.4395180344581604\n",
      "F1 macro: 0.20083966406445555\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.93      0.61      5764\n",
      "           1       0.37      0.41      0.39      2762\n",
      "           2       0.00      0.00      0.00      3650\n",
      "           3       0.00      0.00      0.00      1154\n",
      "           4       0.00      0.00      0.00      1443\n",
      "\n",
      "    accuracy                           0.44     14773\n",
      "   macro avg       0.17      0.27      0.20     14773\n",
      "weighted avg       0.25      0.44      0.31     14773\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "accuracy, f1_macro, report = evaluate_model(loaded_model, test_padded_sequences, test_labels,'DL')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Lt1FX6sZ43Gu",
   "metadata": {
    "id": "Lt1FX6sZ43Gu"
   },
   "source": [
    "## LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1e089dec",
   "metadata": {
    "id": "1e089dec"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Bidirectional,LSTM\n",
    "\n",
    "embedding_dim = 64\n",
    "lstm_units = 64\n",
    "\n",
    "# Define model architecture\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_seq_length))\n",
    "model.add(Bidirectional(LSTM(units=lstm_units)))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(units=5, activation='sigmoid'))\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "51074671",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "51074671",
    "outputId": "592a39f1-5034-4ace-af59-e0db70df4c96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2078/2078 [==============================] - 68s 30ms/step - loss: 0.2328 - accuracy: 0.7418 - val_loss: 0.1832 - val_accuracy: 0.8027\n",
      "Epoch 2/10\n",
      "2078/2078 [==============================] - 24s 12ms/step - loss: 0.1614 - accuracy: 0.8297 - val_loss: 0.1812 - val_accuracy: 0.8066\n",
      "Epoch 3/10\n",
      "2078/2078 [==============================] - 22s 11ms/step - loss: 0.1464 - accuracy: 0.8457 - val_loss: 0.1830 - val_accuracy: 0.8069\n",
      "Epoch 4/10\n",
      "2078/2078 [==============================] - 24s 11ms/step - loss: 0.1345 - accuracy: 0.8587 - val_loss: 0.1862 - val_accuracy: 0.8032\n",
      "Epoch 5/10\n",
      "2078/2078 [==============================] - 21s 10ms/step - loss: 0.1231 - accuracy: 0.8697 - val_loss: 0.1971 - val_accuracy: 0.7965\n",
      "Epoch 6/10\n",
      "2078/2078 [==============================] - 23s 11ms/step - loss: 0.1123 - accuracy: 0.8824 - val_loss: 0.2101 - val_accuracy: 0.7968\n",
      "Epoch 7/10\n",
      "2078/2078 [==============================] - 23s 11ms/step - loss: 0.1023 - accuracy: 0.8927 - val_loss: 0.2317 - val_accuracy: 0.7936\n",
      "Epoch 8/10\n",
      "2078/2078 [==============================] - 23s 11ms/step - loss: 0.0934 - accuracy: 0.9019 - val_loss: 0.2495 - val_accuracy: 0.7870\n",
      "Epoch 9/10\n",
      "2078/2078 [==============================] - 22s 11ms/step - loss: 0.0857 - accuracy: 0.9093 - val_loss: 0.2657 - val_accuracy: 0.7889\n",
      "Epoch 10/10\n",
      "2078/2078 [==============================] - 22s 10ms/step - loss: 0.0777 - accuracy: 0.9172 - val_loss: 0.2927 - val_accuracy: 0.7867\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_padded_sequences, train_labels, epochs=10, batch_size=64,\n",
    "                    validation_data=(test_padded_sequences,test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jOzSgVo545-H",
   "metadata": {
    "id": "jOzSgVo545-H"
   },
   "source": [
    "## Evalution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b4814a09",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b4814a09",
    "outputId": "b097e6d8-0424-4721-e277-dd8026e5f730",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "462/462 [==============================] - 2s 5ms/step - loss: 0.2927 - accuracy: 0.7867\n",
      "462/462 [==============================] - 3s 4ms/step\n",
      "Accuracy: 0.786705493927002\n",
      "F1 macro: 0.746936223754875\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.87      0.85      5764\n",
      "           1       0.80      0.81      0.80      2762\n",
      "           2       0.75      0.76      0.76      3650\n",
      "           3       0.73      0.64      0.68      1154\n",
      "           4       0.68      0.61      0.64      1443\n",
      "\n",
      "    accuracy                           0.79     14773\n",
      "   macro avg       0.76      0.74      0.75     14773\n",
      "weighted avg       0.78      0.79      0.79     14773\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy, f1_macro, report = evaluate_model(model, test_padded_sequences, test_labels,'DL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "OOSeQtdLJ6V6",
   "metadata": {
    "id": "OOSeQtdLJ6V6"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
